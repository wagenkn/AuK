{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirische Analyse\n",
    "\n",
    "Weiß man zu wenig über den Entwurf eines (z.B. als ausführbares Programm) vorliegenden Algorithmus', so ist es oft nicht möglich, dessen Aufwand mit analytischen Methoden zu bestimmen. Dann hilft eine *empirische Analyse*. Dabei misst man, wie lange der Algorithmus zur Berechnung der gesuchten Resultate benötigt, und versucht einen funktionalen Zusammenhang $T: n\\mapsto T(n)$ herauszufinden.  \n",
    "\n",
    "Die empirische Analyse macht es notwendig, $k$ Messungen mit unterschiedlichen Eingaben gleicher Größe $n$ durchzuführen. Man betrachtet verschiedene Probleminstanzen, z.B. $k=10$, für jeden betrachteten Wert ein und dieselben Problemgröße, z.B. $n=100,1000,10000,100000,1000000$. \n",
    "\n",
    "Zur Auswertung kann man für jedes $n$ das arithmetische Mittel der $k$ vorlegenden Messwerte, nehmen. Dies liefert den Aufwand im *mittleren Fall* (average case). Nimmt man den jeweils größten/kleinsten Wert, ergibt sich der Aufwand im *schlechtesten* bzw. *besten* Fall (worst/best case).\n",
    "\n",
    "Zur grafischen Darstellung kann man die gemittelten Werte in einem Streudiagramm (scatter plot) eintragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import statistics\n",
    "from time import perf_counter_ns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_minimum(lst):                    # zu bewertendes Programm\n",
    "    min_so_far = float('inf')\n",
    "    for n in lst:\n",
    "        min_so_far = min(min_so_far, n)\n",
    "    return min_so_far\n",
    "\n",
    "def get_random_lst(size, min_value=0, max_value=100000):\n",
    "    lst = []\n",
    "    for i in range(size):\n",
    "        lst.append(random.randint(min_value, max_value))\n",
    "    return lst\n",
    "\n",
    "def measure_time(algorithm):\n",
    "    def helper(*args):\n",
    "        start = perf_counter_ns()   \n",
    "        algorithm(*args)\n",
    "        stop = perf_counter_ns()\n",
    "        return stop - start    \n",
    "    return helper\n",
    "\n",
    "x = list(map(lambda n: 2 * n * 10 ** 4, list(range(1, 6))))\n",
    "y = list(map(lambda x: statistics.median(list(map(lambda _: measure_time(find_minimum)(get_random_lst(x)), range(5)))), x))\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('problem size n')\n",
    "plt.ylabel('elapsed time')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Ein solches Streudiagramm lässt den funktionalen Zusammenhang oft schon erahnen. Besser ist es, wenn wir objektiv(!), d.h. mit mathematischen Mitteln, eine Funktion bestimmen, die den Zusammenhang zwischen $n$ und $T(n)$ ausdrückt. Dies entspricht dem Hineinlegen einer Kurve, die dem Punkteverlauf möglichst gut entspricht und Ausreißer geeignet verarbeitet. \n",
    "\n",
    "Diese Technik wird Regression genannt. Am besten ist es, wenn man eine Gerade verwenden kann. Man spricht von *linearer Regression*. Dies gilt zunächst natürlich nur für lineare Zusammenhänge zwischen $n$ und $T(n)$. Vermutet man eine Polynom- oder Exponentialfunktion, so kann man die Messwerte in vielen Fällen so aufbereiten (umrechnen), dass die daraus gewonnenen Daten durch eine lineare Funktion approximiert werden können. Eine entsprechende Rückrechnung liefert dann die konkreten Koeffizienten der gesuchten Funktion. \n",
    "\n",
    "### Lineare Regression\n",
    "\n",
    "Wie oben angekündigt, suchen wir eine lineare Funktion, die als Gerade die Punkte möglichst gut annähert.\n",
    "\n",
    "Eine lineare Funktion $f$ ist wie folgt definiert:\n",
    "\n",
    "$$\n",
    "f(x) = a \\cdot x + b \\text{ mit $a, b \\in \\mathbb{R}$}\n",
    "$$\n",
    "\n",
    "Nun geht es darum, $a$ und $b$ so zu wählen, dass der Verlauf der Gerade möglichst gut mit dem Verlauf der Punkte übereinstimmt. Hierfür wird die Methode der kleinsten Qudrate (nach Gauss) angewandt: Die Summe der Abstandsquadrate aller Punkte von der Geraden soll möglichst klein sein (Optimierungsziel). Dass dabei die einzelnen Abstandswerte quadriert werden müssen, liegt daran, dass zur Bestimmung des Minimums die erste Ableitung der Abstandsfunktion gebildet wird. Diese ist an der Stelle $x=0$ nicht differenzierbar, nimmt man die Quadrate, dann schon.\n",
    "\n",
    "<img src=\"https://www.astro.rug.nl/software/kapteyn-beta/_images/kmpfit_Pearsonsdata_compare.png\" width=\"300\">\n",
    "<!-- img src=\"http://cs.wellesley.edu/~cs199/lectures/line-fit-errors.png\" width=\"300\" -->\n",
    "\n",
    "- $x_i$ : $x$-Wert des $i$-ten Punktes\n",
    "- $y_i$ : $y$-Wert des $i$-ten Punktes\n",
    "\n",
    "$$\n",
    "e(a, b) = \\sum_{i=1}^n (a \\cdot x_i + b - y_i)^2\n",
    "$$\n",
    "\n",
    "Das Minimum lässt sich analytisch bestimmen, indem man die partiellen Ableitungen von $e(a, b)$ bildet und diese gleich 0 setzt.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "e(a, b) & = \\sum_{i=1}^n \\left((a x_i + b)^2 - 2 \\cdot (a x_i + b) \\cdot y_i + y_i^2\\right) \\\\\n",
    "& = \\sum_{i=1}^n \\left(a^2 x_i^2 + 2 a x_i b + b^2 - 2 a x_i y_i - 2 b y_i + y_i^2\\right) \\\\\n",
    "\\frac{\\partial e(a, b)}{\\partial a} & = \\sum_{i=1}^n \\left(2 x_i^2 a + 2 x_i b - 2 x_i y_i\\right) \\\\\n",
    "& = 2 \\sum_{i=1}^n \\left(x_i^2 a + x_i b - x_i y_i\\right) \\\\\n",
    "& = 2 \\left( \\sum_{i=1}^n x_i^2 a + \\sum_{i=1}^n x_i b - \\sum_{i=1}^n x_i y_i \\right) \\\\\n",
    "& = 2 a \\sum_{i=1}^n \\left(x_i^2 + b \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i y_i \\right) \\\\\n",
    "\\frac{\\partial e(a, b)}{\\partial b} & = \\sum_{i=1}^n \\left(2 a x_i + 2 b - 2 y_i\\right) \\\\\n",
    "& = 2 \\sum_{i=1}^n \\left(a x_i + b - y_i\\right) \\\\\n",
    "& = 2 \\left( \\sum_{i=1}^n a x_i + \\sum_{i=1}^n b - \\sum_{i=1}^n y_i \\right) \\\\\n",
    "& = 2 \\left( a \\sum_{i=1}^n x_i + n b - \\sum_{i=1}^n y_i \\right) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nun müssen die partiellen Ableitungen gleich 0 gesetzt werden.\n",
    "\n",
    "Im folgenden werden $\\overline{x}$ als das arithmetische Mittel von $x$ : $\\overline{x} = \\frac{\\sum_{i=1}^n x_i}{n}$ und $\\overline{y}$ als das arithmetische Mittel von $y$ : $\\overline{y} = \\frac{\\sum_{i=1}^n y_i}{n}$ bezeichnet.\n",
    "\n",
    "$$\n",
    "\\left\\{ \n",
    "\\begin{array}{c}\n",
    "\\begin{align*}\n",
    "2 \\left( a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i y_i \\right) & = 0 \\\\\n",
    "2 \\left( a \\sum_{i=1}^n x_i + n b - \\sum_{i=1}^n y_i \\right) & = 0\n",
    "\\end{align*}\n",
    "\\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{ \n",
    "\\begin{array}{c}\n",
    "\\begin{align*}\n",
    "a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i - \\sum_{i=1}^n x_i y_i & = 0 \\\\\n",
    "a \\sum_{i=1}^n x_i + n b - \\sum_{i=1}^n y_i & = 0\n",
    "\\end{align*}\n",
    "\\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left\\{ \n",
    "\\begin{array}{c}\n",
    "\\begin{align*}\n",
    "a \\sum_{i=1}^n x_i^2 + b \\sum_{i=1}^n x_i & = \\sum_{i=1}^n x_i y_i \\\\\n",
    "a \\sum_{i=1}^n x_i + nb & = \\sum_{i=1}^n y_i\n",
    "\\end{align*}\n",
    "\\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "$$\n",
    "a \\sum_{i=1}^n x_i + nb = \\sum_{i=1}^n y_i \\\\\n",
    "\\iff b = \\frac{\\sum_{i=1}^n y_i - a \\sum_{i=1}^n x_i}{n} \\iff b = \\overline{y} - a \\overline{x} \\\\\n",
    "\\implies a \\sum_{i=1}^n x_i^2 + \\frac{\\sum_{i=1}^n y_i - a \\sum_{i=1}^n x_i}{n} \\sum_{i=1}^n x_i = \\sum_{i=1}^n x_i y_i \\\\\n",
    "\\iff a \\sum_{i=1}^n x_i^2 + \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n} - a \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n} = \\sum_{i=1}^n x_i y_i \\\\\n",
    "\\iff a \\sum_{i=1}^n x_i^2 - a \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n} = \\sum_{i=1}^n x_i y_i - \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n} \\\\\n",
    "\\iff a \\left( \\sum_{i=1}^n x_i^2 - \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n} \\right) = \\sum_{i=1}^n x_i y_i - \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n} \\\\\n",
    "\\iff a = \\frac{\\sum_{i=1}^n x_i y_i - \\frac{\\sum_{i=1}^n x_i \\sum_{i=1}^n y_i}{n}}{\\sum_{i=1}^n x_i^2 - \\frac{\\left( \\sum_{i=1}^n x_i \\right)^2}{n}} \\\\\n",
    "\\iff a = \\frac{\\sum_{i=1}^n x_i y_i - \\frac{n \\cdot \\overline{x} \\cdot n \\cdot \\overline{y}}{n}}{\\sum_{i=1}^n x_i^2 - \\frac{n \\cdot \\overline{x} \\cdot n \\cdot \\overline{x}}{n}} \\\\\n",
    "\\iff a = \\frac{\\sum_{i=1}^n x_i y_i - n \\cdot \\overline{x} \\cdot \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\cdot \\overline{x}^2}\n",
    "$$\n",
    "\n",
    "Nun hat man mit \n",
    "\n",
    "$$\n",
    "a = \\frac{\\sum_{i=1}^n x_i y_i - n \\cdot \\overline{x} \\cdot \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\cdot \\overline{x}^2}\n",
    "$$ \n",
    "\n",
    "und \n",
    "\n",
    "$$\n",
    "b = \\overline{y} - a \\overline{x}\n",
    "$$ \n",
    "\n",
    "Formeln, mit denen man die beiden Koeffizienten der linearen Funktion bestimmen kann.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png\" width=\"350\">\n",
    "\n",
    "### Exponentielle Regression\n",
    "\n",
    "Bei der exponentiellen Regression möchte man eine Exponentialfunktion finden, die sich möglichst gut an die gegebenen Punkte anschmiegt. Dieses Problem lässt sich auf lineare Regression zurückführen, indem man die **y-Achse logarithmisch** anlegt. Nun verläuft die Kurve geradlinig, wenn sie eine Exponentialfunktion darstellt. Deshalb lässt sich das bereits bekannte Verfahren der linearen Regression anwenden.\n",
    "\n",
    "Wählt man als Basis $2$, so möchte man eine Funktion der Form $f(x) = a \\cdot 2^{bx}$ finden. Logarithmiert man den Funktionwert, so erhält man: \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\log_2 \\left(f(x) \\right) & = \\log_2 \\left(a \\cdot 2^{bx} \\right) \\\\\n",
    "& = \\log_2 a + \\log_2 2^{bx} \\\\\n",
    "& = \\log_2 a + bx\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Es handelt sich um eine lineare Funktion und $b$ und $\\log_2 a$ lassen sich wie oben beschrieben bestimmen.\n",
    "\n",
    "\n",
    "### Polynomielle Regression\n",
    "\n",
    "Bei der polynomiellen Regression möchte man eine Funktion der Form $f(x) = a \\cdot x^k$ finden, die die Punkte möglichst gut annähert. Deshalb müssen Konstanten $a$ und $k$ gefunden werden, für die der Fehler minimal ist.\n",
    "\n",
    "Hierfür wird wieder das Logarithmieren der Achsen benutzt. Jedoch wird hier nicht nur die **y-Achse**, sondern auch die **x-Achse logarithmiert**. Die Basis des Logarithmus ist frei wählbar, es muss sich jedoch bei der x- und y-Achse um die gleiche Basis handeln.\n",
    "\n",
    "__Beispiele:__\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LogLog_exponentials.svg/512px-LogLog_exponentials.svg.png\" width=\"300\">\n",
    "\n",
    "Durch Logarithmieren der y-Achse erhält man $y'$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x) &= a \\cdot x^k \\\\\n",
    "\\implies \\log(f(x)) &= \\log(a \\cdot x^k) \\\\\n",
    "\\implies \\log(f(x)) &= k \\log(x) + \\log(a)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Setzt man nun die x-Achse (mit $x'$ gekennzeichnet) $x' = \\log(x)$, so erhält man eine Gerade. $\\log(a)$ gibt den y-Achsenschnittpunkt und $k$ den Anstieg der Geraden an.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(x) &= a \\cdot x^k \\\\\n",
    "\\implies \\log(f(x)) &= \\log(a \\cdot x^k) \\\\\n",
    "\\implies \\log(f(x)) &= k \\log(x) + \\log(a)\\\\\n",
    "\\implies y' &= k x' + \\log(a)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nun kann man wie bei der linearen Regression vorgehen und $k$ und $\\log(a)$ bestimmen.\n",
    "\n",
    "### Korrelationskoeffizient\n",
    "\n",
    "Der Pearson-Korrelationskoeffizient $r$ ist ein Maß für die Beziehung zwischen zwei Variablen. Im Zusammenhang der linearen Regression kann er genutzt werden, um die Qualität der Regressiongerade zu bestimmen.\n",
    "\n",
    "$$\n",
    "r = \\frac{cov(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "$$\n",
    "\n",
    "$cov(X, Y)$ ist die Kovarianz von $X$ und $Y$ und wird folgendermaßen bestimmt:\n",
    "$$\n",
    "cov(X, Y) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y})\n",
    "$$\n",
    "\n",
    "Eingesetzt ergibt sich für $r$ folgende Formel:\n",
    "\n",
    "$$\n",
    "r = \\frac{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y})}{\\sqrt{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\overline{y})^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "r = \\frac{\\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2}}\n",
    "$$\n",
    "\n",
    "Laut der Cauchy-Schwartz-Ungleichung gilt:\n",
    "\n",
    "$$\n",
    "\\left| \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y}) \\right|^2 \\leqslant \\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2 \\implies \\sum_{i=1}^n (x_i - \\overline{x}) (y_i - \\overline{y}) \\leqslant \\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2} \\sqrt{\\sum_{i=1}^n (y_i - \\overline{y})^2} \\implies \\left| r \\right| \\leqslant 1 \\implies -1 \\leqslant r \\leqslant 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lösen von Rekurrenzgleichungen\n",
    "\n",
    "Viele Algorithmen lassen sich rekursiv formulieren. Aus rekursiven Definitionen kann die Aufwandsfunktion $T$ unmittelbar, d.h. offensichtlich und ohne zusätzliche Rechnung abgelesen werden. D.h., es ergibt sich so etwas wie $T(n)=\\ldots T(g(n))\\ldots$. Wir suchen jedoch einen *expliziten Zusammenhang* zwischen $T(n)$ und $n$, d.h. ohne Rekursion. Die Problemlösung wird verlagert. Also benötigen wir für die Effizienzanalyse solcher Algorithmen ein allgemeingültiges Verfahren, das diese rekursiven Gleichungen (Rekurrenzgleichungen) löst.\n",
    "\n",
    "## Regressionsgerade bestimmen\n",
    "\n",
    "Ein typisches Beispiel ist die Fibonacci-Folge: $0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55,\\ldots$.\n",
    "\n",
    "Die Bildungsvorschrift der $n$-ten Fibonacci-Zahl lässt sich sehr leicht angegeben, wenn dies rekursiv geschieht:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "fib(0) & = & 0 \\\\\n",
    "fib(1) & = & 1 \\\\\n",
    "fib(n) & = & fib(n - 1) + fib(n - 2) \\mid n \\geqslant 2\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Die $n$-te Fibonacci-Zahl ist gleich der Summe der zwei vorhergehenden Fibonacci-Zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181]\n"
     ]
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return fib(n-1) + fib(n-2)\n",
    "\n",
    "print(list(map(fib, list(range(0, 20)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Zeitaufwand lässt sich (als Funktion) daraus *unmittelbar* ablesen und durch eine *rekursive* Definition ausdrücken:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "T(0) & = & 0 \\\\\n",
    "T(1) & = & 1 \\\\\n",
    "T(n) & = & T(n - 1) + T(n - 2), n\\geqslant 2\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "Für $T$ benötigen wir einen Ausdruck in $n$ allerdings ohne $T(i)$ auf der rechten Seite.\n",
    "Wir gewinnen diesen Ausdruck dadurch, dass wir die Funktionswerte berechnen und - wie oben ausgeführt - eine zugehörige Regressionsgerade bestimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raten und Einsetzen\n",
    "\n",
    "Eine solche Lösungsmethode ist das __Intelligent guesswork__ - das geschickte Raten. Hierfür stellt man eine Wertetabelle für $T(n)$ auf und versucht daraus eine explizite Bildungsvorschrift zu erkennen.\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T(1) & = 1 \\\\\n",
    "T(n) & = 3 \\cdot T \\left(\\frac{n}{2} \\right) + n\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$n$ sei hierbei eine Zweierpotenz, d.h. $n = 2^k$ mit $k \\in \\mathbb{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Implementierung mit Python verwenden wir die pandas-Bibliothek zur Verwaltung und Analyse von Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     T(n)\n",
      "2       5\n",
      "4      19\n",
      "8      65\n",
      "16    211\n",
      "32    665\n",
      "64   2059\n",
      "128  6305\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def T(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return 3 * T(n/2) + n\n",
    "\n",
    "\n",
    "args = list(map(lambda n: 2**n, list(range(1, 8))))\n",
    "\n",
    "print(pd.DataFrame({'T(n)': pd.Series(map(T, args), index=args, dtype=int)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibt man zusätzlich zu den Funktionswerten die Summendarstellungen an, ergibt sich folgende Wertetabelle:\n",
    "\n",
    "|$n$|$T(n)$|\n",
    "|---:|---:|\n",
    "|$1$|$1$|\n",
    "|$2$|$5=3 \\cdot 1 + 2$|\n",
    "|$4$|$19=3^2 \\cdot 1 + 3 \\cdot 2 + 2^2$|\n",
    "|$8$|$65=3^3 \\cdot 1 + 3^2 \\cdot 2 + 3 \\cdot 2^2 + 2^3$|\n",
    "|$16$|$211=3^4 \\cdot 1 + 3^3 \\cdot 2 + 3^2 \\cdot 2^2 + 3 \\cdot 2^3 + 2^4$|\n",
    "|$32$|$665=3^5 \\cdot 1 + 3^4 \\cdot 2 + 3^3 \\cdot 2^2 + 3^2 \\cdot 2^3 + 3 \\cdot 2^4 + 2^5$|\n",
    "\n",
    "Mit Hilfe dieser Summendarstellung lässt sich ein gewisses Muster erkennen, dadurch kann die Lösung \"erraten\" werden.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(2^k) & = 3^k \\cdot 2^0 + 3^{k-1} \\cdot 2^1 + ... + 3^1 \\cdot 2^{k-1} + 3^0 \\cdot 2^k \\\\\n",
    " & = \\sum_{i=0}^{k}(3^{k-i} \\cdot 2^i) \\\\\n",
    " & = 3^k \\sum_{i=0}^k \\left(\\frac{2}{3} \\right)^i \\\\\n",
    " & = 3^k \\frac{1- \\left(\\frac{2}{3}^{k+1} \\right)}{1-\\frac{2}{3}} \\\\\n",
    "T(2^k) & = 3^{k+1} - 2^{k+1}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Um eine Funktion $n \\mapsto T(n)$ zu erhalten, muss $k$ durch $\\log_2 n$ ersetzt werden.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 3^{\\log_2 n + 1} - 2^{\\log_2 n + 1} \\\\\n",
    " & = 3^{\\log_2 n} \\cdot 3^1 - 2^{\\log_2 n} \\cdot 2^1 \\\\\n",
    " & = 3 \\cdot 3^{\\log_2 n} - 2 \\cdot 2^{\\log_2 n} \\\\\n",
    "T(n) & = 3 \\cdot n^{\\log_2 3} - 2 \\cdot n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Um die asymptotische Aufwandsordnung anzugeben, können der Summand $-2n$ und der Faktor $3$ vernachlässigt werden. Dies ergibt $\\mathcal{O}(n^{\\log_2 3})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Iterationsmethode\n",
    "\n",
    "Bei der __Iterationsmethode__ wird eine rekursive Vorschrift solange angewandt, bis man zu einem rekursionsfreien Ausdruck gelangt. Dies geschieht durch wiederholtes Einsetzen der rekursiven Funktionsaufrufe. Diese Expansion durch Selbstanwendung wird __Telescoping__ genannt.\n",
    "\n",
    "Hat man eine rekursive Funktion $n\\mapsto T(n)$ und setzt man für $n$ einen konkreten Wert ein, so kann problemlos Telescoping angewandt werden, da in endlich vielen Schritten die Elementarfälle erreicht werden und ein rekursionsfreier Ausdruck entsteht. Möchte man aber eine rekursive Funktion $n\\mapsto T(n)$ für ein allgemeines $n$ mit Hilfe der Iterationsmethode lösen, so ist ein mathematischer Zwischenschritt nötig.\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(1) & = 1 \\\\\n",
    "T(n) & = 2 \\cdot T \\left(\\frac{n}{4} \\right) + n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Die Gleichung wird nun schrittweise expandiert:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 2 \\cdot T \\left(\\frac{n}{4} \\right) + n \\\\\n",
    " & = 2 \\cdot \\left(2 \\cdot T \\left(\\frac{n}{16} \\right) + \\frac{n}{4} \\right) + n \\\\\n",
    " & = 4 \\cdot T \\left(\\frac{n}{16} \\right) + \\frac{3}{2}n \\\\\n",
    " & = 4 \\cdot \\left(2 \\cdot T \\left(\\frac{n}{64} \\right) + \\frac{n}{16} \\right) + \\frac{3}{2}n \\\\\n",
    " & = 8 \\cdot T \\left(\\frac{n}{64} \\right) + \\frac{7}{4}n \\\\\n",
    " & = 8 \\cdot \\left(2 \\cdot T \\left(\\frac{n}{256} \\right) + \\frac{n}{64} \\right) + \\frac{7}{4}n \\\\\n",
    " & = 16 \\cdot T \\left(\\frac{n}{256} \\right) + \\frac{15}{8}n \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Es wird ein gewisses Muster für den gesuchten, $T(n)$ definierenden Ausdruck ersichtlich, welches sich mit einer Variable $i$ mit $i\\geqslant 1$ ausdrücken lässt.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 2^i \\cdot T \\left(\\frac{n}{4^i} \\right) + \\frac{2^i - 1}{2^{i-1}} \\cdot n \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Nun muss $i$ so gewählt werden, dass aus $T\\left(\\frac{n}{4^i}\\right)$ ein rekursionsfreier Ausdruck ensteht, d.h. der Elementarfall erreicht ist. Dies geschieht mit $i = \\log_4 n$ bei $T(1)$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T\\left(\\frac{n}{4^i}\\right) & = T(1) \\\\\n",
    "\\frac{n}{4^i} & = 1 \\\\\n",
    "n & = 4^i \\\\\n",
    "i & = \\log_4 n\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Wir setzen $\\log_4 n$ für $i$ in dem oben für $T(n)$ angegebenen \"Musterausdruck\" ein:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = 2^{\\log_4 n} \\cdot T \\left(\\frac{n}{4^{\\log_4 n}} \\right) + \\frac{2^{\\log_4 n} - 1}{2^{\\log_4 n - 1}} \\cdot n \\\\\n",
    " & = n^{\\log_4 2} \\cdot T(1) + \\frac{n^{\\log_4 2} - 1}{\\frac{2^{\\log_4 n}}{2}} \\cdot n \\\\\n",
    " & = n^{\\log_4 2} \\cdot T(1) + \\frac{n^{\\log_4 2} - 1}{\\frac{n^{\\log_4 2}}{2}} \\cdot n \\\\\n",
    " & = n^{\\frac{1}{2}} \\cdot T(1) + \\frac{n^{\\frac{1}{2}} - 1}{\\frac{n^{\\frac{1}{2}}}{2}} \\cdot n \\\\\n",
    " & = n^{\\frac{1}{2}} + \\frac{2n^{\\frac{1}{2}} - 2}{n^{\\frac{1}{2}}} \\cdot n \\\\\n",
    " & = n^{\\frac{1}{2}} + \\frac{2n^{\\frac{3}{2}} - 2n}{n^{\\frac{1}{2}}} \\\\\n",
    " & = n^{\\frac{1}{2}} + \\frac{2n^{\\frac{3}{2}} - 2n}{n^{\\frac{1}{2}}} \\\\\n",
    " & = n^{\\frac{1}{2}} + 2n - 2n^\\frac{1}{2} \\\\\n",
    "T(n) & = 2n - n^\\frac{1}{2}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Interessiert man sich nur für die asymptotische Aufwandsordnung, so liegt mit $T(n) \\in \\mathcal{O}(n)$ ein linearer Zusammenhang vor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meistermethode (Master method)\n",
    "\n",
    "Die __Meistermethode__ bietet eine Möglichkeit, die asymptotische Aufwandsordnung für <a href=\"08%20-%20Divide%20and%20Conquer.ipynb\">Divide and Conquer-Algorithmen</a> anzugeben. Der Zeitaufwand von Divide and Conquer-Algorithmen lässt sich in der Form \n",
    "$$T(n) = a \\cdot T \\left(\\frac{n}{b} \\right) + f(n)$$ angeben. \n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "Für $T(n) = 2 \\cdot T \\left(\\frac{n}{4} \\right) + n$ ergeben sich $a$, $b$ und $f(n)$ durch pattern matching:\n",
    "$$\n",
    "\\begin{eqnarray} \n",
    "a & = 2 \\\\\n",
    "b & = 4 \\\\\n",
    "f(n) & = n\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "<div class=\"general-text\">\n",
    "Nun muss man versuchen, den Ausdruck in einen der folgenden drei Fälle einzuordnen. Wenn dies gelingt, ergibt sich die Lösung unmittelbar aus der Variablenbindung. Wenn nicht, ist die Mastermethode zur Lösung der vorliegenden Rekurrenzgleichung nicht anwendbar.\n",
    "</div>\n",
    "\n",
    "__Definition 2.1 (Master Theorem)__\n",
    "\n",
    "### Fall 1\n",
    "\n",
    "Wenn $f(n) \\in \\mathcal{O} \\left(n^{\\log_b a - \\epsilon} \\right)$ mit $\\epsilon > 0$, dann $T(n) \\in \\Theta \\left(n^{\\log_b a} \\right)$.\n",
    "\n",
    "Der größte Aufwand besteht hier im Teilen in Subprobleme, die Rekursion ist somit wurzellastig (root-heavy).\n",
    "\n",
    "### Fall 2\n",
    "\n",
    "Wenn $f(n) \\in \\Theta \\left(n^{\\log_b a} \\right)$, dann $T(n) \\in \\Theta \\left(n^{\\log_b a}\\log n \\right)$.\n",
    "\n",
    "Der Aufwand zum Rekombinieren der gelösten Subprobleme ist gleichwertig mit dem des Teilens.\n",
    "\n",
    "### Fall 3\n",
    "\n",
    "Wenn $f(n) \\in \\Omega \\left(n^{\\log_b a + \\epsilon} \\right)$ mit $\\epsilon > 0$, dann $T(n) \\in \\Theta(f(n))$.\n",
    "\n",
    "In diesem Fall liegt der größte Aufwand im Rekombinieren, die Rekursion ist also blattlastig (leaf-heavy).\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "Für das oben angegebene Beispiel gilt Fall 3 des Master Theorems.\n",
    "\n",
    "Setzt man $a=2, b=4$ und $f(n)=n$ in $f(n) \\in \\Omega \\left(n^{\\log_b a + \\epsilon} \\right)$ ein, so ergibt sich $n \\in \\Omega \\left(n^{\\log_4 2 + \\epsilon} \\right) = \\Omega \\left(n^{\\frac{1}{2} + \\epsilon} \\right) = \\Omega(n^1)$. Hieraus folgt $\\epsilon=\\frac{1}{2} > 0$.\n",
    "\n",
    "Folglich gilt für die Aufwandsordnung $T(n)\\in\\Theta(n)$. Das Verfahren arbeitet mit linearem Aufwand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
