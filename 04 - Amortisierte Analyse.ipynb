{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amortisierte Analyse\n",
    "\n",
    "Nicht immer ist die Angabe der worst-case-Komplexität hilfreich. Sie ist manchmal viel zu schlecht, nämlich dann, wenn der worst case nur sehr selten eintritt, aber in den meisten Fällen eine wesentlich bessere Laufzeit erzielt wird. Dies ist z.B. beim Hinzufügen von Elementen in einem dynamischen Array der Fall. Obwohl das meistens mit einem Aufwand von $\\mathcal{O}(1)$ möglich ist, wird davon ausgegangen, dass die Array-Kapazität verdoppelt werden muss, was mit dem Umkopieren der vorhandenen Feldelemente und damit einem Aufwand von $\\mathcal{O}(n)$ einher geht. Dadurch liegt die worst-case-Komplexität bei $\\mathcal{O}(n)$, was zunächst abschreckend wirkt, denn andere Datenstrukturen können dies (selbst im worst-case) in $\\mathcal{O}(1)$. \n",
    "\n",
    "Offensichtlich erhalten wir ein präziseres Analyseergebnis, wenn wir\n",
    "* eine Folge von Operationen (statt nur einer) und\n",
    "* ggf. die Reihenfolge von Operationen\n",
    "im worst case betrachten.\n",
    "\n",
    "Genau dies erreichen wir mit der _amortisierten Analyse_.\n",
    "\n",
    "Die amortisierte Analyse (amortized analysis) berechnet die mittleren Kosten über eine Folge von Operationen, in der viele dieser Operationen billig sind und nur wenige teuer in Bezug auf deren Beitrag zur Gesamtzeit. Sie garantiert die durchschnittliche Performance __jeder__ Operation im worst case (ohne Wahrscheinlichkeiten).\n",
    "\n",
    "\n",
    "## Aggregat-Analyse\n",
    "\n",
    "Wir betrachten eine Folge von $n$ (durchaus verschiedener/verschiedenartiger) Operationen und mitteln deren Gesamtausführungszeit $T(n)$, erhalten also $\\frac{T(n)}{n}$. Fakt ist, dass in der betrachteten Folge der schlechteste Fall sehr selten vorkommt. Einige wenige teure Operationen sind erlaubt, während die Durchschnittskosten niedrig gehalten werden.\n",
    "\n",
    "$$T_{amort}(n) = \\frac{\\text{Summe der Kosten aller $n$ Operationen der Folge}}{n}=\\frac{T(n)}{n}$$\n",
    "\n",
    "Die Summe der Zeitaufwände aller $n$ Operationen der betrachteten Operationenfolge wird durch $n$ dividiert.\n",
    "\n",
    "\n",
    "### Dynamisches Feld\n",
    "\n",
    "Zur Implementation des DT Stack können dynamische Felder verwendet werden.\n",
    "\n",
    "Bei einem dynamischen Feld wird zunächst ein Array der Größe $1$ initialisiert. Immer dann, wenn die Feldgröße erschöpft ist, d.h. push auf letzten freien Platz, wird per resize ein neues Array mit doppelter Länge erstellt. Die Elemente des ursprünglichen Feldes werden in das neue hineinkopiert. Sollte dieses Array nicht mehr ausreichen, so wird es durch ein neues doppelter Länge ersetzt usw.\n",
    "\n",
    "Die push-Operation \"Einfügen eines Elements in ein Array\" wird also sehr oft mit $\\mathcal{O}(1)$ zu bewerkstelligen sein und nur sehr selten $\\mathcal{O}(n)$ für die push- mit resize-Operation erfordern. \n",
    "\n",
    "Wir betrachten eine Folge von push-Operationen ggf. mit resize auf einer anfangs leeren Datenstruktur. Nach dem ersten push findet eine Verdopplung der Feldgröße auf 2 statt, nach dem zweiten push ebenso. Nun stehen 4 Plätze zur Verfügung, sodass nach der dritten push-Operation kein resize ausgeführt wird, wohl aber nach der vierten. Das jeweils aktuelle $n$ gibt die zugehöre Anzahl der Feldelemente an, so dass die ggf. stattfindende resize-Operation mit $\\mathcal{O}(n)$ arbeitet.\n",
    "\n",
    "   n     | push ohne resize | resize | Feldzugriffe      | Feldzugriffe (kumulativ)\n",
    ":------: | :--------------: | :----: | :---------------: | :-------------------:\n",
    "   1     | 1                | 1      | 2                 | 2\n",
    "   2     | 1                | 2      | 3                 | 5\n",
    "   3     | 1                | 0      | 1                 | 6\n",
    "   4     | 1                | 4      | 5                 | 11\n",
    "   5     | 1                | 0      | 1                 | 12\n",
    "   6     | 1                | 0      | 1                 | 13\n",
    "   7     | 1                | 0      | 1                 | 14\n",
    "   8     | 1                | 8      | 9                 | 23\n",
    "   9     | 1                | 0      | 1                 | 24\n",
    "   :     | 1                | 0      | 1                 | :\n",
    "   15    | 1                | 0      | 1                 | 30\n",
    "   16    | 1                | 16     | 17                | 47\n",
    "   :     | :                | :      | :                 | :\n",
    "\n",
    "Aus der Tabelle geht hervor, dass für beliebiges $n$ wenigstens eine push-Operation ohne resize stattfindet. Dafür veranschlagen wir einen Aufwand in Höhe von $n\\cdot\\mathcal{O}(1)=\\mathcal{O}(n).$\n",
    "\n",
    "Ist $n$ eine Zweierpotenz, kommen $1+2+4+8+16+\\ldots+n$ resize-Operationen hinzu. Für $n=16$ bedeutet das (s. Tabelle, 3. Spalte): $1+2+4+8+16=31$ (was dann mit den $16$ push-Operationen $31+16=47$ ergibt) und allgemein: $$\\sum_{i=0}^{\\log_2n}2^i = 2^{\\log_2n+1}-1 = 2\\cdot2^{\\log_2n}-1 = 2n-1,$$ denn es ist eine endliche geometrische Reihe mit $q=2$.\n",
    "\n",
    "Dies ergibt insgesamt $T(n)=n+2n-1=3n-1$, was man an den Tabellenwerten (letzte Spalte von links) für Zweierpotenzen sehr gut überprüfen kann.\n",
    "\n",
    "$$T_{amort}(n) = \\frac{T(n)}{n} = \\frac{\\mathcal{O}(n)}{n} = \\mathcal{O}(1)$$\n",
    "\n",
    "<!--\n",
    "Die amortisierten Kosten betragen:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n)_{amort} & = \\frac{(n-1)\\cdot\\mathcal{O}(1)+1\\cdot\\mathcal{O}(n)}{n}=\\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Alternative amortisierte Analyse\n",
    "\n",
    "$$\\begin{align*}\n",
    "T(n)_{gesamt} & = n + 1 + \\dotsc + 1 + \\frac{n}{2} + 1 + \\dotsc + 1 + \\frac{n}{4} + 1 + \\dotsc + 1 + \\frac{n}{8} + \\dotsc + 1 \\\\\n",
    " & = \\sum_{i=0}^{\\infty} n \\cdot \\left(\\frac{1}{2} \\right)^i  + (n - \\log_2 n) \\cdot 1 \\\\\n",
    " & = n \\cdot \\sum_{i=0}^{\\infty} \\left(\\frac{1}{2}\\right)^i + (n - \\log_2 n) \\cdot 1 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Da es sich bei der Summe um eine geometrische Reihe handelt, kann sie aufgelöst werden.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n)_{gesamt} & = n \\cdot \\frac{1}{1-\\frac{1}{2}} + (n - \\log_2 n) \\cdot 1 \\\\\n",
    " & = 2n + (n - \\log_2 n) \\cdot 1 \\\\\n",
    " & = 2n + \\mathcal{O}(n) \\\\\n",
    " & \\in \\mathcal{O}(n)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n)_{amort} & = \\frac{\\mathcal{O}(n)}{n} \\\\\n",
    " & \\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "-->\n",
    "<!-- <div style=\"text-align: right; font-size: 24px;\">&#9633;</div> --> \n",
    "\n",
    "Damit ergeben sich für die Insert-Opertion bei einem dynamischen Array amortisierte Kosten von $\\mathcal{O}(1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binärzähler\n",
    "\n",
    "Situation: $n$ Inkrementierungen eines $k$-Bit-Binärzählers ($k=\\log_2n$) mit Anfangswert $0$, siehe auch [HPI teaching](https://hpi.de/friedrich/teaching/units/amortisierte-analyse.html)\n",
    "\n",
    "Array: $A[0 \\dotsc k-1],\\ A[i] \\in \\{0,1\\},$\n",
    "\n",
    "$$x = \\sum_{i=0}^{k-1} A[i] \\cdot 2^i$$\n",
    "\n",
    "Aufwand: akkumulierte Anzahl der \"Bit-Klappungen\"\n",
    "\n",
    "Worst case: Alle $k$ Bits werden invertiert, da sie von 1 auf 0 wechseln. Dies ist beim Übergang von $2^i - 1$ zu $2^i$ der Fall. Folglich beträgt der Aufwand je Inkrementierungsschritt im schlechtesten Fall $\\mathcal{O}(k) = \\mathcal{O}(\\log_2n)$. Dies ist zwar korrekt, aber zu grob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A[6]  A[5] A[4] A[3] A[2] A[1] A[0]  Total costs\n",
      "0      0     0    0    0    0    0    0            0\n",
      "1      0     0    0    0    0    0    1            1\n",
      "2      0     0    0    0    0    1    1            3\n",
      "3      0     0    0    0    0    0    1            4\n",
      "4      0     0    0    0    1    1    1            7\n",
      "5      0     0    0    0    0    0    1            8\n",
      "6      0     0    0    0    0    1    1           10\n",
      "7      0     0    0    0    0    0    1           11\n",
      "8      0     0    0    1    1    1    1           15\n",
      "9      0     0    0    0    0    0    1           16\n",
      "10     0     0    0    0    0    1    1           18\n",
      "11     0     0    0    0    0    0    1           19\n",
      "12     0     0    0    0    1    1    1           22\n",
      "13     0     0    0    0    0    0    1           23\n",
      "14     0     0    0    0    0    1    1           25\n",
      "15     0     0    0    0    0    0    1           26\n",
      "16     0     0    1    1    1    1    1           31\n",
      "17     0     0    0    0    0    0    1           32\n",
      "18     0     0    0    0    0    1    1           34\n",
      "19     0     0    0    0    0    0    1           35\n",
      "20     0     0    0    0    1    1    1           38\n",
      "21     0     0    0    0    0    0    1           39\n",
      "22     0     0    0    0    0    1    1           41\n",
      "23     0     0    0    0    0    0    1           42\n",
      "24     0     0    0    1    1    1    1           46\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def increment_cost(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    return n ^ (n-1)\n",
    "\n",
    "\n",
    "def total_costs(bin_strings):\n",
    "    if len(bin_strings) == 0:\n",
    "        return []\n",
    "    total_costs_lst = total_costs(bin_strings[:-1])\n",
    "    if len(total_costs_lst) == 0:\n",
    "        total_cost = 0\n",
    "    else:\n",
    "        total_cost = total_costs_lst[len(total_costs_lst)-1]\n",
    "    for digit in bin_strings[len(bin_strings)-1]:\n",
    "        if digit == \"1\":\n",
    "            total_cost += 1\n",
    "    return total_costs_lst + [total_cost]\n",
    "\n",
    "    \n",
    "A_cost = []\n",
    "max_n = 25\n",
    "inc_costs = []\n",
    "\n",
    "for i in range(0, max_n):\n",
    "    inc_costs.append(\"{0:b}\".format(increment_cost(i)))\n",
    "\n",
    "for i in range(0, 7):\n",
    "    A_cost.append(list())\n",
    "    for j in range(0, max_n):\n",
    "        A_cost[i].append(0)\n",
    "\n",
    "for n in range(0, max_n):\n",
    "    inc_cost = \"{0:b}\".format(increment_cost(n))\n",
    "    for i in reversed(range(0, len(inc_cost))):\n",
    "        A_cost[i][n] = inc_cost[i]\n",
    "        \n",
    "        \n",
    "table = pd.DataFrame({'A[6]': pd.Series(A_cost[6]),\n",
    "                     'A[5]': pd.Series(A_cost[5]),\n",
    "                     'A[4]': pd.Series(A_cost[4]),\n",
    "                     'A[3]': pd.Series(A_cost[3]),\n",
    "                     'A[2]': pd.Series(A_cost[2]),\n",
    "                     'A[1]': pd.Series(A_cost[1]),\n",
    "                     'A[0]': pd.Series(A_cost[0]),\n",
    "                    'Total costs': pd.Series(total_costs(inc_costs))}, \n",
    "                   columns=['A[6]', 'A[5]', 'A[4]', 'A[3]', 'A[2]', 'A[1]', 'A[0]', 'Total costs'])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Die Tabelle zeigt, wann ein Bit invertiert werden muss. In diesem Fall steht eine 1 an dem entsprechenden Index. Man kann beobachten, dass $A[0]$ $n$-mal invertiert wird, $A[1]$ wird in jedem zweiten Schritt invertiert, also $\\frac{n}{2}$-mal, $A[2]$ in jedem vierten Schritt, d.h. $\\frac{n}{4}$-mal. Verallgemeinert kann man sagen, dass $A[i]$ $\\frac{n}{2^i}$-mal, mit $i\\geq 0$, invertiert werden muss. Für die Gesamtkosten ergibt sich also:\n",
    "\n",
    "$$T_{\\text{gesamt}}(n) = \\sum_{i=0}^{k-1} \\frac{n}{2^i} = n \\cdot \\sum_{i=0}^{k-1} \\frac{1}{2^i} < n \\cdot \\sum_{i=0}^{\\infty} \\frac{1}{2^i} = 2n \\in \\mathcal{O}(n)$$\n",
    "\n",
    "$$T(n) = \\frac{\\mathcal{O}(n)}{n} \\in \\mathcal{O}(1)$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "Es ergibt sich also ein amortisierter Aufwand von $\\mathcal{O}(1)$ für die Inkrement-Operation.\n",
    "\n",
    "Die Aggregat Methode ist die einfachste Methode zur amortisierten Analyse, jedoch lassen sich komplexere Algorithmen mit ihr nicht analysieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accounting-Methode\n",
    "\n",
    "Bei der Accounting-Methode gibt es ein Bankkonto, auf welches man Guthaben laden kann. Dieses Guthaben kann man sich als Münzen vorstellen, die eingezahlt werden, wenn eine Operation billig ist, d.h. mit sehr geringem Zeitaufwand ausgeführt wird. Bei Operationen mit hohen Kosten (großer Zeitaufwand) besteht die Möglichkeit, vorhandenes Guthaben vom Konto zu nehmen und damit die Operation zu \"bezahlen\". Der Betrag auf dem Konto darf dabei nicht negativ werden, man möchte nämlich zeigen, dass die tatsächlichen Kosten $\\leqslant$ amortisierte Kosten sind.\n",
    "\n",
    "### Dynamisches Array\n",
    "\n",
    "Hier wird folgendermaßen vorgegangen:\n",
    "\n",
    "- wenn eine Insertion-Operation keine Verdopplung verursacht, zahlt man eine Münze mit dem Wert $\\mathcal{O}(1)$ in das Konto ein.\n",
    "- wenn eine Insertion-Operation eine Verdopplung verursacht, so wurden seit der letzten Verdopplung $\\frac{n}{2}$ Elemente eingefügt. $\\frac{n}{2}$ Münzen können nun verwendet werden um die $\\mathcal{O}(n)$ Operation zu bezahlen.\n",
    "\n",
    "<img src=\"img/table-doubling-accounting-method.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "- amortisierte Kosten für eine Verdopplung: $\\mathcal{O}(n) - c \\cdot \\frac{n}{2} = 0$ für ein $c$, das groß genug ist. (In dem Fall $c=2$)\n",
    "- da $c$ eine Konstante ist, gilt dass die amortisierten Kosten für eine Insert-Operation $1 + c \\in \\mathcal{O}(1)$ sind.\n",
    "\n",
    "\n",
    "## Potenzial-Methode (Potenzialfunktionsmethode)\n",
    "\n",
    "Bei der Potenzial-Methode, bzw. beim Beweis mit Potenzialfunktion, wird eine Funktion definiert, die von einer Datenstruktur in einem bestimmten Zustand auf eine reelle nicht-negative Zahl abbildet. Diesen Wert bezeichnet man als Potenzial. Dieses Konzept ähnelt der Accounting Methode.\n",
    "\n",
    "__Definition 4.2__ Es wird eine Datenstruktur zum Zeitpunkt $i$ als $D_i$ betrachtet. Zu definieren ist also eine Potenzialfunktion $\\Phi : D_i \\rightarrow \\mathbb{R^+_0}$. Die tatsächlichen Kosten einer Operation werden $c_i$ bezeichnet. Für die amortisierten Kosten $\\hat{c}_i$ ergibt sich folgende Gleichung:\n",
    "\n",
    "$$\n",
    "\\hat{c}_i = c_i + \\Delta \\Phi(D_i) = c_i + \\Phi(D_i) - \\Phi(D_{i-1})\n",
    "$$\n",
    "\n",
    "Die amortisierten Kosten einer Operation sind die Summe aus den tatsächlichen Kosten dieser Operation und der Veränderung der Potenzialfunktion, die durch diese Operation verursacht wird. Die Veränderung der Potenzialfunktion ist gleich der Differenz aus $\\Phi$ zum Zeitpunkt $i$ und $\\Phi$ zum Zeitpunkt $i-1$.\n",
    "\n",
    "Intuitiv kann man sagen, dass die Potenzialfunktion angeben soll, wie labil der aktuelle Zustand der Datenstruktur gegenüber teure Operationen ist, d.h. wie nah die nächste teure Operation ist.\n",
    "\n",
    "Aus der Gleichung für die amortisierten Kosten $\\hat{c}_i$ lässt sich eine Gleichung für die amortisierten Kosten aller Operationen von 1 bis $n$ herleiten:\n",
    "\n",
    "__Lemma 4.3__\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^n \\hat{c}_i &= \\sum_{i=1}^n c_i + \\sum_{i=1}^n (\\Phi(D_i) - \\Phi(D_{i-1})) \\\\\n",
    " &= \\sum_{i=1}^n c_i + (\\Phi(D_1) - \\Phi(D_0) + \\Phi(D_2) - \\Phi(D_1) + \\dotsc + \\Phi(D_n) - \\Phi(D_{n-1})) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Bei der Teleskopsumme $\\sum \\Phi(D_i) - \\Phi(D_{i-1})$ kürzen sich alle Terme außer $\\Phi(D_n)$ und $\\Phi(D_0)$. Somit ergibt sich:\n",
    "\n",
    "__Korollar 4.4__\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^n \\hat{c}_i &= \\sum_{i=1}^n c_i + \\Phi(D_n) - \\Phi(D_0) \\\\\n",
    "\\sum \\text{amortisierte Kosten} &= \\sum \\text{tatsächliche Kosten} + \\Phi(\\text{finale Datenstruktur}) - \\Phi(\\text{initiale Datenstruktur})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "### Dynamische Arrays\n",
    "\n",
    "Bei dynamischen Arrays, deren Größe sich verdoppelt, wenn sie voll sind, lässt sich beispielsweise folgende Potenzialfunktion aufstellen:\n",
    "\n",
    "$$\n",
    "\\Phi(D_i) = 2n-m\n",
    "$$\n",
    "\n",
    "$n$ ist dabei die Anzahl der eigentlichen Elemente im dynamischen Array und $m$ ist die Anzahl der allozierten Speicherplätze. Direkt nach einer Verdopplungsoperation ist die Hälfte der Speicherplätze mit Elementen gefüllt, also $n = \\frac{m}{2}$. Damit ist \n",
    "\n",
    "$$\n",
    "\\Phi(D_i) = 2n-m = 2 \\cdot \\frac{m}{2} - m = 0\n",
    "$$\n",
    "\n",
    "$\\Phi(D_i) = 0$ bedeutet, dass die Datenstruktur weit entfernt von der nächsten tueren Operation ist. Kurz vor der Verdopplungsoperation beträgt $n = m$, also ist \n",
    "\n",
    "$$\n",
    "\\Phi(D_i) = 2n - m = 2m - m = m\n",
    "$$\n",
    "\n",
    "Nun kann sowohl für die billige, als auch für die teure Operation bewiesen werden, dass die amortisierten Kosten in beiden Fällen $\\mathcal{O}(1)$ betragen.\n",
    "\n",
    "##### Pushback Operation ohne Speicherallokation\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= c_i + \\Delta \\Phi(D_i) \\\\\n",
    " &= c_i + \\Phi(D_i) - \\Phi(D_{i-1}) \\\\\n",
    " &= 1 + 2(n+1) - m - (2n - m) \\\\\n",
    " &= 1 + 2 \\\\\n",
    " &= 3 \\\\\n",
    " &\\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "##### Pushback Operation mit Speicherallokation\n",
    "\n",
    "In diesem Fall ist das momentane Array voll und es gilt $n = m$:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= c_i + \\Delta \\Phi(D_i) \\\\\n",
    " &= c_i + \\Phi(D_i) - \\Phi(D_{i-1}) \\\\\n",
    " &= n + 1 + 2(n + 1) - 2m - (2n - m) \\\\\n",
    " &= n + 1 + 2 - m \\\\\n",
    " &= n + 1 + 2 - n \\\\\n",
    " &= 3 \\\\\n",
    " &\\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "### Binärzähler\n",
    "\n",
    "Beim Binärzahler könnte man zunächst intuitiv die Anzahl der hinterneinander folgenden Bits, die 1 sind, von hinten, als Potenzialfunktion nehmen. Demnach hätte 01001000 eine kleines Potenzial, ist also weit weg von teuren Operationen, 01111111 hätte demnach ein großes Potenzial, was auch zu stimmen scheint, da die nächste Operation zeitaufwendig sein wird. Betrachtet man aber beispielsweise 11111110, so wäre das Potenzial 0. Eine teure Operation ist also vermeindlich weit entfernt. Jedoch wird die übernächste Operation teuer. Die Anzahl der hinterneinander folgenden 1-Bits von hinten, scheint also keine passende Potenzialfuktion zu sein.\n",
    "\n",
    "Stattdessen ist die Gesamtzahl der 1-Bits der Binärzahl aussagekräftiger. Man spricht auch vom Hamming-Gewicht (hamming weight) der Binärzahl.\n",
    "\n",
    "$\\text{hamming_weight}(01001000) = 2$, $\\text{hamming_weight}(01111111) = 7$, $\\text{hamming_weight}(11111110) = 7$.\n",
    "\n",
    "__Definition 4.5__ Das Hamming-Gewicht einer Zeichenkette ist die Anzahl der vom Nullzeichen des verwendeten Alphabets verschiedenen Zeichen.\n",
    "\n",
    "Auch hier kann gezeigt werden, dass die amortisierten Kosten für eine Inkrementoperation $\\mathcal{O}(1)$ sind.\n",
    "\n",
    "$$\n",
    "\\hat{c}_i = c_i + \\Delta \\Phi(D_i)\n",
    "$$\n",
    "\n",
    "Bei einem Inkrement einer Binärzahl werden alle aufeinanderfolgenden Bits, die 1 sind, zu 0 invertiert und das erste Bit von rechts, das 0 ist, wird zu 1 invertiert. Damit ergeben sich folgende Kosten $c$ für eine Binärzahl mit $t$ aufeinnanderfolgenden 1-Bits von hinten: $c = t + 1$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= t + 1 + \\Delta \\Phi(D_i) \\\\\n",
    " &= t + 1 + \\Phi(D_i) - \\Phi(D_{i-1}) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Das Potenzial $\\Phi(D_{i-1})$ vor der Inkrementoperation ist $\\text{hamming_weight}(b)$. Durch die Inkrementoperation werden $t$ aufeinanderfolgende 1-Bits zu 0, wodurch sich das Hamming-Gewicht um $t$ verkleinert. Das erste 0-Bit von hinten wird zu 1, dadurch vergrößert sich das Hamming-Gewicht um 1. Das Potenzial $\\Phi(D_i)$ nach der Inkrementoperation beträgt demnach $\\text{hamming_weight}(b) - t + 1$.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\hat{c}_i &= t + 1 + \\Delta \\Phi(D_i) \\\\\n",
    " &= t + 1 + (\\text{hamming_weight}(b) - t + 1) - (\\text{hamming_weight}(b)) \\\\\n",
    " &= t + 1 - t + 1 \\\\\n",
    " &= 2 \\\\\n",
    " &\\in \\mathcal{O}(1)\n",
    "\\end{align*}\n",
    "$$\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
