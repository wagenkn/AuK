{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bäume\n",
    "\n",
    "Mathematisch betrachtet ist die Menge der Bäume eine Teilmenge der Menge der ungerichteten Graphen.\n",
    "\n",
    "__Definition__\n",
    "\n",
    "Ein ungerichteter Graph $G = (V, E)$ ist ein *Baum*, wenn es für alle $u, v \\in V$ genau einen Pfad von $u$ nach $v$ gibt.\n",
    "\n",
    "In einem Baum gibt es also zu jedem Knotenpaar genau einen Pfad. Alternativ kann man sagen, dass ein ungerichteter Graph ein Baum ist, wenn er ___zusammenhängend___ ist und ___keine Zyklen___ enthält. Ein Graph ist zusammenhängend, wenn jeder Knoten von jedem anderen Knoten aus erreichbar ist.\n",
    "\n",
    "__Beispiele:__\n",
    "\n",
    "Der folgende Graph\n",
    "\n",
    "<img src=\"img/graph1.png\" width=\"200\">\n",
    "\n",
    "ist ein Baum, da er keine Kreise enthält und zusammenhängend ist.\n",
    "\n",
    "Der folgende Graph\n",
    "\n",
    "<img src=\"img/graph2.png\" width=\"200\">\n",
    "\n",
    "ist __kein__ Baum, da er einen Kreis $(2,4,5)$ enthält. \n",
    "\n",
    "Der folgende Graph\n",
    "\n",
    "<img src=\"img/graph3.png\" width=\"200\">\n",
    "\n",
    "ist __kein__ Baum, da er nicht zusammenhängend ist: Knoten mit dem Wert $7$ ist nicht erreichbar.\n",
    "\n",
    "### Bäume mit Wurzel (Wurzelbäume)\n",
    "\n",
    "In der Informatik betrachtet man meistens Wurzelbäume (rooted trees).\n",
    "\n",
    "__Definition 6.1__\n",
    "\n",
    "_Wurzelbäume_ sind gerichtete oder ungerichtete Bäume, bei denen __genau ein Knoten Wurzel (root)__ ist. Von diesem Wurzelknoten sind alle anderen Knoten über genau einen _Pfad_ (Folge von Knoten, die darin höchstens einmal vorkommen) erreichbar. Der Wurzelknoten ist der einzige Knoten des Graphen, der keinen Vorgänger besitzt.\n",
    "\n",
    "__Beispiel:__\n",
    "\n",
    "<img src=\"http://www.mathcs.emory.edu/~cheung/Courses/170/Syllabus/02/FIGS/tree-stru.gif\" width=\"280\">\n",
    "\n",
    "## Binärbäume\n",
    "\n",
    "__Definition 6.2__\n",
    "\n",
    "_Binärbäume (binary trees)_ sind Bäume mit Wurzel, bei denen jeder Knoten höchstens zwei direkte Nachkommen (Kindknoten) hat. \n",
    "\n",
    "__Beispiel:__ gerichteter Binärbaum\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Binary_tree.svg/720px-Binary_tree.svg.png\" width=\"200\">\n",
    "\n",
    "Dabei besteht ein Knoten (Node) aus genau einem _Wert_ (allg. Schlüssel: key), einem _linken_ und einem _rechten Binärbaum_ mit folgender rekursiver Definition.\n",
    "\n",
    "Für arithmetische Ausdrücke, die ausschließlich Binäroperationen enthalten, können Operatorbäume angegeben werden. Während die inneren Knoten den Operatoren vorbehalten sind, enthalten die Blätter die entsprechenden Operanden.\n",
    "\n",
    "__Beispiel:__ gerichteter Operatorbaum für den Ausdruck $(5-6)+(2\\cdot(3-4))$\n",
    "<img src=\"img/Operatorbaum.jpg\" width=\"300\" >\n",
    "\n",
    "Ein Binärbaum $\\ldots$\n",
    "\n",
    "+ $\\ldots$ ist entweder leer (*null*),\n",
    "+ $\\ldots$ oder besteht aus einem linken und einem rechten Binärbaum.\n",
    "\n",
    "Es ist also möglich, dass genau ein Kind oder beide Kinder aus einem leeren Binärbaum besteht/en. Sind sowohl linkes als auch rechtes Kind *null*, so handelt es sich bei dem betrachteten Knoten um ein *Blatt* (*leaf*).\n",
    "\n",
    "__Definition 6.3__\n",
    "\n",
    "Manchmal wird für Binärbäume zusätzlich gefordert, dass sie *vollständig* sind. Dann müssen alle $k\\geq 0$ *Niveaus* (Schichten) eines Binärbaums die jeweils maximale Knotenanzahl $2^k (k\\geq 0)$ aufweisen und sämtliche Blätter dieselbe *Tiefe* haben.\n",
    "\n",
    "__Definition 6.4__\n",
    "\n",
    "Die _Tiefe $t$ eines **Knotens** $(t\\geq 0)$ ist sein Abstand zur Wurzel, d.h. die Anzahl der Kanten auf dem Pfad von diesem Knoten zum Wurzelknoten. Sämtliche Knoten mit Tiefe $t$ liegen auf _Niveau_ $t$.\n",
    "\n",
    "__Definition 6.5__\n",
    "\n",
    "Die _Höhe $h$ eines **Baumes**_ ist die maximale Tiefe aller Knoten. <br>\n",
    "Dies kann man für einen Baum mit Wurzelknoten $w$ rekursiv definieren: \n",
    "$$h(w)=\\begin{cases}\n",
    "    0, & \\text{wenn } w\\text{ ein Blatt ist.}\\\\\n",
    "    \\max(h(w_1),h(w_2),\\ldots,h(w_r))+1, & \\text{für alle } r \\text{ Kindknoten } w_i\\text{ von } w.\n",
    "  \\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Implementation mit obigem Beispiel__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, value=None, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "\n",
    "a = Node(5)\n",
    "b = Node(11)\n",
    "c = Node(4)\n",
    "d = Node(2)\n",
    "e = Node(6, a, b)\n",
    "f = Node(9, c)\n",
    "g = Node(7, d, e)\n",
    "h = Node(5, None, f)\n",
    "i = Node(2, g, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binäre Suchbäume\n",
    "\n",
    "Ein Binärer Suchbaum (BST = binary search tree) ist eine Datenstruktur, die verwendet wird, wenn sowohl schnelles Einfügen, als auch schnelles Suchen eines Elements gefordert werden.\n",
    "\n",
    "Wir betrachten zunächst Datenstrukturen, die bereits im Kapitel \"Abstrakte Datentypen und Datenstrukturen\" vorgestellt wurden, nämlich eine Linked List, ein unsortiertes und ein sortiertes Array. Dazu untersuchen wir die Worst-case-Aufwände der Insert und Search Operation.\n",
    "\n",
    "Bei einer __Linked List__ findet das Einfügen in $\\mathcal{O}(1)$ statt, da lediglich ein neues Element angelegt und entsprechend ein Pointer bearbeitet wird. Der zum Suchen eines Elements erforderliche Zeitaufwand liegt in $\\mathcal{O}(n)$, da im worst case durch die komplette Liste gegangen werden muss, um das Element zu finden. \n",
    "\n",
    "Bei einem __unsortierten Array__ beträgt der Aufwand zum Einfügen $\\mathcal{O}(n)$, da ein neues Array erstellt werden muss und alle Werte kopiert werden. Wie bei der Linked List muss durch alle Elemente iteriert werden, um ein bestimmtes Element zu finden, dadurch ist auch hier der Aufwand zum Suchen $\\mathcal{O}(n)$.\n",
    "\n",
    "Bei einem __sortierten Array__ kann Binary Search verwendet werden, um ein Element zu finden, dadurch beträgt der Aufwand hierfür lediglich $\\mathcal{O}(\\log n)$. Das Einfügen ist jedoch ineffizient. Man müsste zunächst die Stelle finden, wo das neue Element eingefügt werden soll, um die Sortierung beizubehalten. Dies nimmt $\\mathcal{O}(\\log n)$ in Anspruch. Anschließend muss man allerdings $\\mathcal{O}(n)$ Elemente dahinter um eine Position nach hinten verschieben, bzw. in ein neues Array kopieren. Dadurch ergibt sich für die Insert-Operation ein Aufwand von $\\mathcal{O}(n)$.\n",
    "\n",
    "Ein __Binärer Suchbaum__ ist ein Binärbaum, bei dem für alle Knoten gilt, dass jeder Knotenwert des linken Subbaums kleiner als der Wert des Elternknoten ist und der Wert des Elternknoten kleiner als jeder Knotenwert des rechten Subbaums ist. Dies lässt sich nicht nur für Zahlen anwenden, sondern für alle Datentypen, für die eine Ordnungsrelation definiert ist. So gilt verallgemeinert, dass für jeden Knoten die Relation aus jedem Knotenwert des linken Subbaums und dem Wert des Elternknotens zur definierten Ordnungsrelation gehört, sowie alle Relationen aus dem Wert des Elternknoten und jedem Knotenwert des rechten Subbaums.\n",
    "\n",
    "__Beispiel__\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Binary_search_tree.svg/500px-Binary_search_tree.svg.png\" width=\"200\">\n",
    "\n",
    "__Search__\n",
    "\n",
    "Um einen Wert in einem BST (binary search tree) zu finden, wird ein Verfahren ähnlich wie Binary Search angewandt. Die Suche beginnt bei der Wurzel. Stimmt der gesuchte Wert mit dem der Wurzel überein, so hat man den Knoten gefunden. Ist der gesuchte Wert kleiner als der Wert der Wurzel, so wird die Suche rekursiv mit der Wurzel des linken Subbaums fortgesetzt, da sich hier alle Werte befinden, die kleiner als die Wurzel sind. Ist der gesuchte Wert größer, so wird rekursiv im rechten Subbaum weitergesucht. Der Algorithmus terminiert, sobald der gesuchte Wert gefunden (Knoten gefunden) oder ein Blatt mit anderem Wert (gesuchter Knoten nicht vorhanden) erreicht wurde.\n",
    "\n",
    "Die Höhe des binären Suchbaums im obigen Beispiel beträgt 3.\n",
    "\n",
    "Da bei der Suche im BST maximal $h$ (Höhe $h$ des Baums) Knoten besucht werden, beträgt der Zeitaufwand zur Suche $\\mathcal{O}(h)$. Was dies in Bezug auf $n$ (der Anzahl der Elemente) bedeutet, wird noch erläutert.\n",
    "\n",
    "__Insert__\n",
    "\n",
    "Wir gehen davon aus, dass sich keine Duplikate (Knoten mit dem gleichen Wert) im BST befinden.\n",
    "\n",
    "Um ein Element einzufügen, muss zunächst die Suche im BST durchgeführt werden. Da sich das Element noch nicht im BST befindet, gelangt man an das Blatt, das dem einzufügenden Wert am nächsten ist. An dieser Stelle muss man nun einen neuen Knoten einfügen. Ist der einzufügende Wert größer, so wird er als rechtes Kind eingefügt, ist er kleiner, so wird er als linkes Kind eingefügt.\n",
    "\n",
    "__Remove__\n",
    "\n",
    "Um ein Element (rot, 8) zu entfernen, muss man es zuerst suchen. Dieser Vorgang wurde bereits beschrieben und ist mit einem Aufwand von $\\mathcal{O}(h)$ machbar. Handelt es sich bei dem Element um ein Blatt im Baum, so kann dieses Element einfach entfernt werden.\n",
    "\n",
    "<img src=\"img/bst_removing_leaf.png\" width=\"200\">\n",
    "\n",
    "Handelt es sich bei dem zu löschenden Knoten um einen inneren Knoten der genau ein (linkes oder rechtes) Kind besitzt, so wird dieser Knoten gelöscht und sein Sohn wird der Sohn seines Vorgängers.\n",
    "\n",
    "<img src=\"img/bst_removing_with_1_child.png\" width=\"200\">\n",
    "\n",
    "Hat der zu löschende Knoten zwei Kinder, so muss die entstandene Lücke im Baum gefüllt werden. Dafür wird im rechten Teilbaum der (ganz links stehende) Knoten mit dem kleinsten Wert (blau, 10) gesucht und dieser dort eingesetzt, wo das zu löschende Element (rot, 8) gerade entfernt wurde. Das zum Schließen der Lücke verwendete Element mit dem kleinsten Wert (blau, 10) wird anschließend aus dem rechten Teilbaum entfernt. \n",
    "\n",
    "Alternativ kann man das größte Element des linken Subbaums nehmen. Um das größte Element zu finden, muss man entsprechend immer nach rechts im Baum gehen.\n",
    "\n",
    "<img src=\"img/bst_removing_with_2_children_step_1.png\" width=\"200\">\n",
    "\n",
    "<img src=\"img/bst_removing_with_2_children_step_2.png\" width=\"200\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n",
      "14\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "def search_in_BST(root, value):\n",
    "    if root is None or root.value is None:\n",
    "        return None\n",
    "    if value == root.value:\n",
    "        return root\n",
    "    if value < root.value:\n",
    "        return search_in_BST(root.left, value)\n",
    "    return search_in_BST(root.right, value)\n",
    "\n",
    "\n",
    "def insert_in_BST(root, value):\n",
    "    if root is not None:\n",
    "        if root.value is None:\n",
    "            root.value = value\n",
    "        elif value < root.value:\n",
    "            if root.left is None:\n",
    "                root.left = Node()\n",
    "            insert_in_BST(root.left, value)\n",
    "        elif value > root.value:\n",
    "            if root.right is None:\n",
    "                root.right = Node()\n",
    "            insert_in_BST(root.right, value)\n",
    "          \n",
    "        \n",
    "def amount_of_nodes(root, count=0):\n",
    "    if root is not None:\n",
    "        count += 1 + amount_of_nodes(root.left) + amount_of_nodes(root.right)\n",
    "    return count\n",
    "            \n",
    "\n",
    "def find_min_in_BST(root):\n",
    "    if root is not None:\n",
    "        if root.left is None:\n",
    "            return root\n",
    "        return find_min_in_BST(root.left)\n",
    "    \n",
    "    \n",
    "def find_max_in_BST(root):\n",
    "    if root is not None:\n",
    "        if root.right is None:\n",
    "            return root\n",
    "        return find_max_in_BST(root.right)\n",
    "        \n",
    "\n",
    "def remove_from_BST(root, value):\n",
    "    if root is not None:\n",
    "        if value == root.value:\n",
    "            if root.left is None and root.right is None:\n",
    "                return None\n",
    "            if root.left is None:\n",
    "                return root.right\n",
    "            if root.right is None:\n",
    "                return root.left\n",
    "            root.value = find_min_in_BST(root.right).value\n",
    "            root.right = remove_from_BST(root.right, root.value)\n",
    "        elif value < root.value:\n",
    "            root.left = remove_from_BST(root.left, value)\n",
    "        else:\n",
    "            root.right = remove_from_BST(root.right, value)\n",
    "        return root\n",
    "    \n",
    "    \n",
    "bst = Node()\n",
    "insert_in_BST(bst, 8)\n",
    "insert_in_BST(bst, 3)\n",
    "insert_in_BST(bst, 10)\n",
    "insert_in_BST(bst, 1)\n",
    "insert_in_BST(bst, 6)\n",
    "insert_in_BST(bst, 14)\n",
    "insert_in_BST(bst, 4)\n",
    "insert_in_BST(bst, 7)\n",
    "insert_in_BST(bst, 13)\n",
    "\n",
    "print(bst.left.value)\n",
    "print(bst.right.value)\n",
    "print(bst.right.right.value)\n",
    "print(bst.left.right.right.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oben wurden die Search- und Insert-Operationen eines BST mit dem folgenden Beispiel implementiert:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Binary_search_tree.svg/500px-Binary_search_tree.svg.png\" width=\"200\">\n",
    "\n",
    "Testhalber geben wir einige Werte des BST aus. Sie stimmen mit den erwarteten Werten überein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(search_in_BST(bst, 1).value)\n",
    "print(search_in_BST(bst, 10).value)\n",
    "print(search_in_BST(bst, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Werte 1 und 10 konnten Knoten gefunden werden, für den Wert 2 nicht, da er sich nicht im BST befindet.\n",
    "\n",
    "Mit der Remove-Operation soll der Wurzelknoten mit dem Wert 8 entfernt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nodes: 9\n",
      "10\n",
      "14\n",
      "number of nodes after removing 1 node: 8\n"
     ]
    }
   ],
   "source": [
    "print('number of nodes: ' + str(amount_of_nodes(bst)))\n",
    "bst = remove_from_BST(bst, 8)\n",
    "print(bst.value)\n",
    "print(bst.right.value)\n",
    "print('number of nodes after removing 1 node: ' + str(amount_of_nodes(bst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Traversal (Baumdurchlauf)\n",
    "\n",
    "Um einen Baum zu traversieren, benutzt man Depth-First-Search. Da es sich bei einem Binärbaum nicht um eine Liste von benachbarten Knoten handelt, sondern um zwei Pointer auf je einen Kindknoten, wird DFS hier nicht auf eine Liste, sondern auf die beiden Kinder rekursiv angewandt. \n",
    "\n",
    "Fährt man mit dem Finger entlang der jeweiligen Kante zu einem Kindknoten, so ergeben sich drei Berührungen:\n",
    "1. Berührung direkt durch Eintreffen entlang der Kante\n",
    "2. Berührung nach dem \"Abfahren\" des linken Teilbaums \n",
    "3. Berührung nach dem \"Abfahren\" des rechten Teilbaums \n",
    "\n",
    "Die Position der Druckanweisung bezogen auf die Folge der Knotenberührungen bestimmt, ob es sich um __Pre-Order__, __In-Order__ oder __Post-Order__ Traversal handelt.\n",
    "\n",
    "#### Pre-Order Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_order_trav(root):\n",
    "    if root is not None:\n",
    "        print(root.value, end=' ')\n",
    "        pre_order_trav(root.left)\n",
    "        pre_order_trav(root.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Pre-Order Traversal wird direkt beim ersten Besuch des Knotens die gewünschte Aktion auf dem Knoten ausgeführt, in dem Fall das Ausgeben des Wertes des Knotens. Erst danach folgen die rekursiven Aufrufe auf den beiden Kindern.\n",
    "\n",
    "#### In-Order Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_order_trav(root):\n",
    "    if root is not None:\n",
    "        in_order_trav(root.left)\n",
    "        print(root.value, end=' ')\n",
    "        in_order_trav(root.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei In-Order Traversal findet zunächst der rekursive Aufruf auf dem linken Kind statt, danach die Aktion auf dem Knoten und anschließend der rekursive Aufruf auf dem rechten Kind. Dies hat zur Folge, dass die Aktion immer beim zweiten Besuch eines Knoten ausgeführt wird.\n",
    "\n",
    "Führt man In-Order Traversal auf einem Binären Suchbaum aus, so werden die Werte in sortierter Reihenfolge ausgegeben.\n",
    "\n",
    "#### Post-Order Traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_order_trav(root):\n",
    "    if root is not None:\n",
    "        post_order_trav(root.left)\n",
    "        post_order_trav(root.right)\n",
    "        print(root.value, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Post-Order Traversal finden zunächst die rekursiven Aufrufe statt und anschließend die Aktion auf dem Knoten. Dies hat zur Folge, dass die Aktion beim dritten Besuch eines Knoten stattfindet.\n",
    "\n",
    "Für das Beispiel\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Binary_search_tree.svg/500px-Binary_search_tree.svg.png\" width=\"200\">\n",
    "\n",
    "ergeben sich folgende Reihenfolgen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre order:\n",
      "8 3 1 6 4 7 10 14 13 \n",
      "in order:\n",
      "1 3 4 6 7 8 10 13 14 \n",
      "post order:\n",
      "1 4 7 6 3 13 14 10 8 "
     ]
    }
   ],
   "source": [
    "bst = Node()\n",
    "insert_in_BST(bst, 8)\n",
    "insert_in_BST(bst, 3)\n",
    "insert_in_BST(bst, 10)\n",
    "insert_in_BST(bst, 1)\n",
    "insert_in_BST(bst, 6)\n",
    "insert_in_BST(bst, 14)\n",
    "insert_in_BST(bst, 4)\n",
    "insert_in_BST(bst, 7)\n",
    "insert_in_BST(bst, 13)\n",
    "\n",
    "print('pre order:')\n",
    "pre_order_trav(bst)\n",
    "print()\n",
    "print('in order:')\n",
    "in_order_trav(bst)\n",
    "print()\n",
    "print('post order:')\n",
    "post_order_trav(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Höhe eines binären Suchbaums\n",
    "\n",
    "Wir haben festgestellt, dass man in einem gewöhnlichen binären Suchbaum mit einem Zeitaufwand von $\\mathcal{O}(h)$ ein Element finden kann, wobei $h$ die Höhe des Baums ist. Die Höhe eines Baums ist die Länge des Pfades (Anzahl der Kanten) zum am weitesten von ihm entfernten Blatt. Dies kann folgendermaßen rekursiv definiert werden:\n",
    "\n",
    "__Definition 6.6__\n",
    "$$\n",
    "\\text{height}(n) = \\begin{cases}\n",
    "    -1, & \\text{wenn $n=$ null}. \\\\\n",
    "    \\text{max}\\{\\text{height}(n.\\text{left}), \\text{height}(n.\\text{right})\\} + 1, & \\text{sonst}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Existiert der Knoten nicht, so ist die Höhe -1. Besteht der Baum aus genau einem Knoten, so ist der Weg zum Blatt 0, also ist die Höhe 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "def height_of_tree(root):\n",
    "    if root is None:\n",
    "        return -1\n",
    "    return max(height_of_tree(root.left), height_of_tree(root.right)) + 1\n",
    "\n",
    "\n",
    "print(height_of_tree(bst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist gut zu wissen, dass für die Suche eines Elements in einem binären Suchbaum $\\mathcal{O}(h)$ gilt. Wir erwarten jedoch einen Ausdruck in $n$ für den asymptotischen Aufwand in Abhängigkeit von der Anzahl der Elemente im BST?\n",
    "\n",
    "Im Idealfall haben wir es mit einem _balancierten_ BST zu tun:\n",
    "\n",
    "<img src=\"http://opendatastructures.org/versions/edition-0.1d/ods-java/img908.png\" width=\"330\">\n",
    "\n",
    "Ein BST ist _balanciert_, wenn bei jedem Knoten der linke Subbaum genauso viele Elemente enthält, wie der rechte Subbaum.\n",
    "\n",
    "Hat der Baum die Höhe $h$, so besitzt er höchstens $n=2^0+2^1+2^2+\\ldots+2^h=2^{h+1}-1$ Knoten/Elemente (endliche geometrische Reihe). Dann gilt $\\frac{n+1}{2}=2^h,\\ \\log_2(n+1)-1 = h$ und damit liegt $h$ in $\\mathcal{O}(\\log_2n)$.\n",
    "Ist der Binärbaum balanciert, so beträgt der Aufwand zum Suchen $\\mathcal{O}(\\log n)$. Dies ist genau unser Ziel.\n",
    "\n",
    "Jedoch sieht ein BST leider nicht immer so aus. Fügt man beispielsweise eine bereits sortierte Liste hintereinander in einen BST ein, so erhält man einen BST wie diesen:\n",
    "\n",
    "<img src=\"http://3.bp.blogspot.com/-UND30lJuXOw/Upxep4tLvpI/AAAAAAAAAGA/CjDC8VJ2aI8/s1600/s_fig33.gif\" width=\"250\">\n",
    "\n",
    "Dies entspricht eher einer linearen Liste als einem Binärbaum. Es ist offensichtlich, dass hier der Aufwand zum Suchen linear in $n$ und nicht logarithmisch ist.\n",
    "\n",
    "## AVL-Bäume\n",
    "Gesucht ist also ein Verfahren, mit welchem man sicherstellt, dass ein Binärer Suchbaum so balanciert wie möglich ist. Der historisch erste Vorschlag (1962) geht auf Adelson-Velskij und Landis zurück: __AVL-Bäume__.\n",
    "\n",
    "__Definition 6.7__\n",
    "Bei einem AVL-Baum gilt für jeden Knoten $n$ folgende Invariante:\n",
    "\n",
    "$$\n",
    "\\lvert \\text{height}(n.\\text{right}) - \\text{height}(n.\\text{left}) \\rvert \\leqslant 1\n",
    "$$\n",
    "\n",
    "Die Höhe des linken Subbaums unterscheidet sich maximal um 1 von der Höhe des rechten Subbaums.\n",
    "\n",
    "Ideal wäre, wenn bei jedem Knoten der rechte Subbaum die gleiche Höhe hat wie der linke Subbaum. Doch so ein perfekt balancierter Binärbaum ist nur möglich, wenn er $2^n - 1 , n \\in \\mathbb{N}$ Knoten hat. Weiter unten zeigen wir, dass auch unter der Bedingung, dass sich die Höhen um nicht mehr als 1 unterscheiden, man trotzdem eine logarithmische Laufzeit erzielt.\n",
    "\n",
    "### Insert\n",
    "\n",
    "Zunächst findet das Einfügen eines neuen Elements wie bei einem gewöhnlichen BST statt. Man sucht zunächst nach einem Knoten mit dem einzufügenden Wert, um es dann an passender Stelle einfügen.\n",
    "\n",
    "Bei einem gewöhnlichen BST wird jedoch nicht sichergestellt, dass die oben beschriebene Invariante nach dem Einfügen gilt. Bei einem AVL-Baum ist also nach dem Einfügen eine Operation anzuwenden, die genau das gewährleistet.\n",
    "\n",
    "Betrachten wir das Beispiel:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Binary_search_tree.svg/500px-Binary_search_tree.svg.png\" width=\"200\"/>\n",
    "\n",
    "Hier ist die Invariante des AVL-Baums verletzt, da der rechte Subbaum (Wurzel 10) eine Höhe von 1 und der linke Subbaum eine Höhe von -1 haben. Sie unterscheiden sich also um mehr als 1.\n",
    "\n",
    "#### Rotationen\n",
    "\n",
    "<!-- <img src=\"http://www.dgp.toronto.edu/people/JamesStewart/378notes/17rbInsertion/d_RB09.gif\" width=\"350\"> -->\n",
    "\n",
    "Bei $\\alpha$, $\\beta$ und $\\gamma$ handelt es sich um Subbäume, die in der Abb. als Dreiecke angedeutet werden.\n",
    "\n",
    "Man kann einfach zeigen, dass eine Rotation nichts an der Gültigkeit des Binären Suchbaums, also an der Sortierung der Elemente, ändert. Führt man nämlich In-Order Traversal in beiden Fällen durch, so kommt man jeweils auf das gleiche Ergebnis:\n",
    "\n",
    "$$\n",
    "\\alpha y \\beta x \\gamma\n",
    "$$\n",
    "\n",
    "Dieses Rotationsverfahren kann nun genutzt werden, um die Balancierung (die Höhen der beiden Subbäume) anzupassen, ohne die Sortierung des BST zu verändern. Mitunter sind auch zwei Rotation nach einer Insert-Operation nötig, um die AVL-Baum-Invariante herzustellen.\n",
    "\n",
    "Im folgenden Beispiel wurde gerade die 7 eingefügt. Die Invariante des AVL-Baums ist verletzt.\n",
    "\n",
    "<img src=\"http://lh4.ggpht.com/-Ab8FnH1hzDI/UKkev6oPgjI/AAAAAAAABmA/ZEwc8xGKCyw/clip_image016_thumb1.gif?imgmax=800\" width=\"200\">\n",
    "\n",
    "Führt man eine linke Rotation auf dem Knoten mit dem Wert 6 aus, so wird die Invariante wieder erfüllt.\n",
    "\n",
    "<img src=\"http://lh4.ggpht.com/-3BuZjyaMkHw/UKkezqHgIII/AAAAAAAABmQ/XNrniYzMnuw/clip_image018_thumb1.gif?imgmax=800\" width=\"200\">\n",
    "\n",
    "Hier war lediglich eine Rotation nötig, um die Gültigkeit des AVL-Baums wiederherzustellen.\n",
    "\n",
    "Betrachten wir folgendes Beispiel, so stellen wir fest, dass nun eine Art \"Zick-Zack Pfad\" existiert.\n",
    "\n",
    "<img src=\"http://lh6.ggpht.com/-_gxwudL7nn8/UKke7AvUqNI/AAAAAAAABmw/OnEVuPtFRtE/clip_image022_thumb1.gif?imgmax=800\" width=\"200\">\n",
    "\n",
    "Hier sind zwei Rotationen, eine sogenannte Doppelrotation (double rotation), nötig. Als erste Rotation wird der Knoten mit dem Wert 15 nach rechts rotiert. Dadurch ergibt sich folgender Zustand:\n",
    "\n",
    "<img src=\"img/avl_tree_double_rotation_1.png\" width=\"250\">\n",
    "\n",
    "Nun haben wir ein bereits bekanntes Problem und müssen den Knoten mit dem Wert 15 nach links rotieren.\n",
    "\n",
    "<img src=\"img/avl_tree_double_rotation_2.png\" width=\"250\">\n",
    "\n",
    "Die Invariante des AVL-Baums gilt nun wieder.\n",
    "\n",
    "Es gibt also zwei Fälle, bei denen eine Rotation im Baum nötig ist.\n",
    "\n",
    "__Fall 1__\n",
    "\n",
    "Dieser Fall tritt ein, wenn bei einem Knoten der rechte Subbaum um 2 höher ist als der linke Subbaum und das rechte Kind entweder einen um 1 höheren rechten Subbaum hat oder balanciert ist (beide Subbäume sind gleich groß).\n",
    "\n",
    "Dieser Fall liegt beispielsweise hier vor:\n",
    "\n",
    "<img src=\"http://lh4.ggpht.com/-Ab8FnH1hzDI/UKkev6oPgjI/AAAAAAAABmA/ZEwc8xGKCyw/clip_image016_thumb1.gif?imgmax=800\" width=\"200\">\n",
    "\n",
    "Wie bereits oben beschrieben wurde, ist nun eine linke Rotation auf dem Knoten mit dem Wert 6 nötig.\n",
    "\n",
    "Dieser Fall 1 tritt ebenfalls ein, wenn bei einem Knoten der linke Subbaum um 2 höher ist als der rechte Subbaum und das linke Kind entweder einen um 1 höheren linken Subbaum hat oder balanciert ist.\n",
    "\n",
    "__Fall 2__\n",
    "\n",
    "Dieser Fall ist der \"Zick-Zack\"-Fall. Er tritt ein, wenn bei einem Knoten der rechte Subbaum um 2 höher ist als der linke Subbaum und das rechte Kind einen linken Subbaum hat, der um 1 höher ist als der rechte Subbaum. Natürlich gilt das auch entsprechend symmetrisch, also tritt dieser Fall 2 auch ein, wenn bei einem Knoten der linke Subbaum um 2 höher ist als der rechte Subbaum und das linke Kind einen rechten Subbaum hat, der um 1 höher ist als der linke Subbaum.\n",
    "\n",
    "Dieser Fall wurde ebenfalls oben anhand dieses Beispiels gezeigt:\n",
    "\n",
    "<img src=\"http://lh6.ggpht.com/-_gxwudL7nn8/UKke7AvUqNI/AAAAAAAABmw/OnEVuPtFRtE/clip_image022_thumb1.gif?imgmax=800\" width=\"200\">\n",
    "\n",
    "Es ist eine Doppelrotation nötig.\n",
    "\n",
    "### Komplexitätsanalyse\n",
    "\n",
    "Der Aufwand zum Suchen beträgt $\\mathcal{O}(h)$. Für einen gewöhnlichen BST haben wir festgestellt, dass im worst-case $h = n$ gilt und somit der Aufwand zum Suchen $\\mathcal{O}(n)$ ist.\n",
    "\n",
    "Bei einem AVL-Baum haben wir jedoch folgende Regel, die den Baum bis zu einem gewissen Grad balanciert hält:\n",
    "\n",
    "$$\n",
    "\\lvert \\text{height}(n.\\text{right}) - \\text{height}(n.\\text{left}) \\rvert \\leqslant 1\n",
    "$$\n",
    "\n",
    "Diese Ungleichung kann genutzt werden, um den Aufwand zum Suchen in einem AVL-Baum abzuschätzen. Zunächst schauen wir uns an, wie viele Knoten $n$ ein AVL-Baum der Höhe $h$ mindestens hat. Hierfür betrachten wir den worst-case. Der worst-case tritt ein, wenn bei allen Knoten des Baums die Höhen der Subbäume sich um 1 in immer die gleiche Richtung unterscheiden. Es gibt also zwei worst-cases, entweder ist bei allen Knoten der rechte Subbaum um 1 höher als der linke Subbaum oder bei allen Knoten ist der linke Subbaum um 1 höher als der rechte Subbaum.\n",
    "\n",
    "Nun kann die Anzahl der Knoten $n$ in Abhängigkeit von der Höhe $h$ im worst-case AVL-Baum rekursiv beschrieben werden. Einer der beiden Subbäume - sagen wir der rechte - hat die Höhe $h - 1$, da sich die Höhe des Baums aus dem Maximum der Höhen der beiden Subbäume addiert mit 1 ergibt. Da der linke Subbaum laut Definition des worst-case AVL-Baums eine Höhe hat, die um 1 kleiner als die des rechten Subbaums ist, hat dieser eine Höhe von $h - 2$. Die Anzahl der Knoten eines Baums ist die Anzahl der Knoten der beiden Subbäume addiert mit 1, da der Elternknoten selbst mitgezählt werden muss. Die Elementarfälle treten ein, wenn die Höhe des Baums -1 ist, in diesem Fall besteht er aus keinem Knoten, oder die Höhe des Baums 0 ist, in diesem Fall besteht der Baum aus genau einem Knoten.\n",
    "\n",
    "$$\n",
    "n(h) = \\begin{cases}\n",
    "0 , & \\text{wenn $h = -1$.} \\\\\n",
    "1 , & \\text{wenn $h = 0$.} \\\\\n",
    "n(h-1) + n(h-2) + 1 , & \\text{sonst.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Für die asymptotische Analyse spielen die Elementarfälle keine Rolle. Es reicht aus zu wissen, dass es Konstanten sind.\n",
    "\n",
    "$$\n",
    "n(h) = n(h-1) + n(h-2) + 1\n",
    "$$\n",
    "\n",
    "Da $n(h-1) > n(h-2)$, gelten folgende Ungleichungen:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "n(h) & > n(h-2) + n(h-2) + 1 \\\\\n",
    "     & > 2 n(h-2) + 1 \\\\\n",
    "     & > 2 n(h-2) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Aus der letzten Ungleichung folgt, dass sich $n$ in jedem Schritt verdoppelt. Es gibt insgesamt $\\frac{h}{2}$ Schritte, da in jedem Schritt $h$ um zwei größer wird. Es gilt also $n(h) \\in \\Theta(2^{\\frac{h}{2}})$. Durch Umformen erhält man $h \\in \\Theta(2 \\log n) = \\Theta(\\log n)$. Die Höhe $h$ ist also logarithmisch im Bezug auf $n$ beschränkt. Daraus folgt, dass der Aufwand zum Suchen eines Elements in $\\mathcal{O}(\\log n)$ liegt. Zum Einfügen eines Wertes muss zunächst nach einem Element dieses Wertes gesucht werden und danach folgt eine konstante Zahl an Pointeroperationen. Damit ist der Aufwand zum Einfügen $\\mathcal{O}(\\log n) + \\mathcal{O}(1) = \\mathcal{O}(\\log n)$.\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "# Binäre Heaps\n",
    "\n",
    "(Binäre) Heaps implementieren den ADT *Priority Queue*. Eine *Priority Queue* ist eine lineare Datenstruktur, bei dem jedes Element eine Priorität hat und man jederzeit das Element mit der höchsten (bzw. niedrigsten) Priorität aufrufen kann.\n",
    "\n",
    "Ein Binärer Heap (binary heap) stellt einen Binärbaum dar, der mit einem Array implementiert wird. Dabei werden die Indices im Baum entsprechend nach Ebene und von links nach rechts durchgezählt. Man beginnt mit 1.\n",
    "\n",
    "<img src=\"http://i0.wp.com/upload.wikimedia.org/wikipedia/commons/1/15/Heap_mat_entspriechendem_Tableau_dozou.png?resize=350%2C260\" width=\"350\">\n",
    "\n",
    "Durch diese Konvention, benötigt man keine spezielle Implementierung des Baums, denn ein Array reicht aus. Ist die Länge des Arrays kleiner als $2^n - 1, n \\in \\mathbb{N}$, so bleiben in der untersten Ebene Knoten rechts unbesetzt.\n",
    "\n",
    "Außerdem sind der Elternknoten und die beiden Kinder des Knoten mit dem Index $i$ komfortabel erreichbar.\n",
    "\n",
    "- Index des Elternknoten des Knoten mit dem Index $i$: $\\lfloor \\frac{i}{2} \\rfloor$\n",
    "- Index des linken Kindes des Knoten mit dem Index $i$: $2i$\n",
    "- Index des rechten Kindes des Knoten mit dem Index $i$: $2i+1$\n",
    "\n",
    "## Min-Heap und Max-Heap\n",
    "\n",
    "__Definition 6.8__ \n",
    "Bei einem Min-Heap gilt, dass jeder Knoten einen kleineren Wert hat als seine Kinder (sofern er denn Kinder hat).\n",
    "\n",
    "__Definition 6.9__\n",
    "Bei einem Max-Heap gilt, dass jeder Knoten einen größeren Wert hat als seine Kinder (sofern er denn Kinder hat).\n",
    "\n",
    "Durch diese Tatsache befindet sich bei einem Max-Heap das Element mit dem höchsten Wert in der Wurzel. Der Widerspruchsbeweis ist einfach zu führen. Angenommen das größte Element ist nicht die Wurzel, so hat es einen Elternknoten. Dieser hat auf Grund der Max-Heap Eigenschaft einen höheren Wert. Hier liegt der Widerspruch vor.\n",
    "\n",
    "Dies und alles folgende für Max-Heaps gilt analog für Min-Heaps.\n",
    "\n",
    "### heapify\n",
    "\n",
    "__heapify__ ist eine Operation, die auf einem Max- bzw. Min-Heap angewandt werden kann, um eine Verletzung der Max- bzw. Min-Heap Eigenschaft in Ordnung zu bringen. \n",
    "\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQEvZ3lLXikOaswsqw5sfNnOy2_BdDIbnYZExyIGG3AIj6xcrYq\" width=\"300\">\n",
    "\n",
    "In diesem Beispiel verletzt der Knoten mit dem Index 1 die Max-Heap Eigenschaft. Die Bedingung, damit heapify angewandt werden kann, dass die beiden Subbäume Max-Heaps sind, ist erfüllt. Um die Verletzung der Max-Heap Eigenschaft zu beheben, kann die 3 mit der 10 (der größere Wert der beiden Kinder) vertauscht werden. Nun muss heapify rekursiv auf das Kind aufgerufen werden, dass vertauscht wurde, denn es kann sein, dass durch das Vertauschen die Max-Heap Eigenschaft im Subbaum verletzt wird. Dies ist in dem Beispiel in der Tat der Fall, so dass die 3 mit der 5 vertauscht wird. Der Algorithmus terminiert, sobald die Max-Heap Eigenschaft nicht verletzt ist. Dies ist spätestens beim Blatt der Fall, da er keine Kinder hat und somit die Max-Heap Eigenschaft nicht verletzen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 5, 8, 3, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "def max_heapify(heap, i):\n",
    "    # only do something if node has a child\n",
    "    if i < len(heap)/2:\n",
    "        # checks if left child is largest element\n",
    "        if heap[2*i-1] > heap[i-1] and heap[2*i-1] > heap[2*i]:\n",
    "            heap[i-1], heap[2*i-1] = heap[2*i-1], heap[i-1]\n",
    "            return max_heapify(heap, 2*i)\n",
    "        # checks if right child is largest element\n",
    "        elif heap[2*i] > heap[i-1]:\n",
    "            heap[i-1], heap[2*i] = heap[2*i], heap[i-1]\n",
    "            return max_heapify(heap, 2*i+1)\n",
    "    return heap\n",
    "\n",
    "\n",
    "print(max_heapify([3, 10, 8, 5, 2, 4], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da sich die Höhe $h$ des Baums durch $\\log n$ aus der Anzahl $n$ der Elemente ergibt und maximal $h$-mal heapify mit einem konstanten Aufwand aufgerufen wird, beträgt die Zeitkomplexität für heapify $\\mathcal{O}(\\log n)$.\n",
    "\n",
    "### build max-heap\n",
    "\n",
    "__build max-heap__ ist eine Operation, mit der man ein beliebiges unsortiertes Array so umsortiert, dass anschließend die Max-Heap Eigenschaft hergestellt ist.\n",
    "\n",
    "Bei diesem Algorithmus wird auf dem Eingabearray mit der Länge $n$ von $\\lfloor \\frac{n}{2} \\rfloor$ bis 1, in dieser Reihenfolge, die max-heapify Operation aufgerufen. Es reicht aus bei $\\lfloor \\frac{n}{2} \\rfloor$ anzufangen, da alle Elemente nach $\\lfloor \\frac{n}{2} \\rfloor$ keine Kinder haben und demnach die Max-Heap Eigenschaft an diesem Knoten nicht verletzt sein kann. Dies ist einfach zu verifizieren, da der letzte Knoten den Index $n$ hat und somit sein Elternknoten per Heap-Definition den Index $\\lfloor \\frac{n}{2} \\rfloor$. Dieser Elternknoten ist der letzte Knoten, der ein Kind hat, da alle weiteren Knoten Kinder mit einem Index haben, der außerhalb des Arrays liegt. Dadurch, dass man rückwärts iteriert, ist sichergestellt, dass an den beiden Kindern die Max-Heap Eigenschaft gilt, da es entweder Blätter sind oder die Kinder bereits abgearbeitet wurden, da sie einen höheren Index haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 5, 3, 1, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "def build_max_heap(arr):\n",
    "    for i in reversed(range(1, int(len(arr)/2) + 1)):\n",
    "        arr = max_heapify(arr, i)\n",
    "    return arr\n",
    "\n",
    "\n",
    "print(build_max_heap([5, 3, 2, 8, 1, 9, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Komplexitätsanalyse\n",
    "\n",
    "Es werden in der Schleife $\\mathcal{O}(n)$ Iterationen durchgeführt. Die heapify Operation hat einen Aufwand von $\\mathcal{O}(\\log n)$. Damit beträgt der Zeitaufwand für build max-heap Operation $\\mathcal{O}(n \\log n)$.\n",
    "\n",
    "Dies kann jedoch noch etwas genauer untersucht werden. Genau genommen beträgt der Aufwand für heapify $\\mathcal{O}(l)$. $l$ ist dabei das Level, von unten gezählt, auf welchem sich der Knoten befindet. Es ist ersichtlich, dass es $\\frac{n}{4}$ Knoten mit Level 1 gibt, $\\frac{n}{8}$ Knoten mit Level 2, $\\frac{n}{16}$ Knoten mit Level 3, $\\dotsc$ und einen Knoten mit Level $\\log n$. Auf Grund dieser Tatsache können wir eine Summe definieren, die den Gesamtaufwand für die Schleife angibt.\n",
    "\n",
    "$$\n",
    "T(n) = \\frac{n}{4} (1 \\cdot c) + \\frac{n}{8} (2 \\cdot c) + \\frac{n}{16} (3 \\cdot c) + \\dotsc + 1 (\\log n \\cdot c)\n",
    "$$\n",
    "\n",
    "Die Konstante $c$ ist dabei eine beliebige Konstante, die den Aufwand für heapify an einem Knoten beschreibt.\n",
    "\n",
    "Da es sich bei den Brüchen immer um Zweierpotenzen handelt, können wir $\\frac{n}{4} = 2^k$ setzen und $c$ ausklammern, um den Ausdruck zu vereinfachen.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "T(n) & = c \\cdot 2^k \\left(\\frac{1}{2^0} + \\frac{2}{2^1} + \\frac{3}{2^2} + \\dotsc + \\frac{k+1}{2^k} \\right) \\\\\n",
    "     & = c \\cdot 2^k \\sum_{i=0}^{k} \\frac{i+1}{2^i}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Mit Hilfe des Quotientenkriteriums kann man zeigen, dass die Reihe \n",
    "$$\n",
    "\\lim_{k \\to \\infty} \\sum_{i=0}^{k} \\frac{i+1}{2^i}\n",
    "$$\n",
    "konvergiert und somit eine Konstante darstellt.\n",
    "\n",
    "$$\n",
    "L = \\lim_{n \\to \\infty} \\left| \\frac{a_{n+1}}{a_n} \\right| = \\lim_{n \\to \\infty} \\left| \\frac{\\frac{n+2}{2^{n+1}}}{\\frac{n+1}{2^n}} \\right| = \\lim_{n \\to \\infty} \\left| \\frac{n+2}{2^{n+1}} \\cdot \\frac{2^n}{n+1} \\right| = \\lim_{n \\to \\infty} \\left| \\frac{n+2}{2 \\cdot 2^n} \\cdot \\frac{2^n}{n+1} \\right| = \\lim_{n \\to \\infty} \\left| \\frac{n+2}{2n+2} \\right| = \\frac{1}{2} < 1 \\implies \\lim_{k \\to \\infty} \\sum_{i=0}^{k} \\frac{i+1}{2^i} \\text{ ist konvergent}\n",
    "$$\n",
    "\n",
    "Diese Konstante können wir $d$ nennen.\n",
    "\n",
    "$$\n",
    "T(n) = c \\cdot 2^k \\cdot d = c \\cdot d \\cdot \\frac{n}{4} \\in \\mathcal{O}(n)\n",
    "$$\n",
    "\n",
    "<div style=\"text-align: right; font-size: 24px;\">&#9633;</div>\n",
    "\n",
    "Es kann also mit $\\mathcal{O}(n)$ eine kleinere obere Schranke für die __build max-heap__ Operation angegeben werden.\n",
    "\n",
    "## Heap Sort\n",
    "\n",
    "Die Heap Datenstruktur kann für ein effizientes Sortierverfahren genutzt werden. Dafür wird nach __build max-heap__ entsprechend die Max-Heap Struktur vom zu sortierenden Array erstellt. Es ist nun klar, dass das größte Element in der Wurzel ist, also in A[1] und demnach direkt dem Heap entnommen werden kann. Diese Lücke wird gefüllt, indem das Element A[n] nun an die Stelle von A[1] gesetzt wird. Nun muss die Max-Heap Struktur mit __max-heapify__ wiederhergestellt werden. Dieser Vorgang wird $n$-mal wiederholt, bis alle Elemente entsprechend sortiert dem Heap entnommen wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 7, 5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def heap_sort(arr):\n",
    "    sorted_arr = []\n",
    "    heap = build_max_heap(arr)\n",
    "    while len(heap) > 0:\n",
    "        sorted_arr.append(heap[0])\n",
    "        heap[0] = heap[-1] # heap[-1] returns the last element from the array\n",
    "        del heap[-1]\n",
    "        heap = max_heapify(heap, 1)\n",
    "    return sorted_arr\n",
    "\n",
    "\n",
    "print(heap_sort([5, 1, 8, 2, 7, 3, 4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die __build max-heap__ Operation hat, wie oben gezeigt wurde, einen Aufwand von $\\mathcal{O}(n)$. Der Aufwand innerhalb der Schleife ist durch den Aufwand von __heapify__ bestimmt. Dieser ist $\\mathcal{O}(\\log n)$. In der Schleife gibt es $n$ Iterationen. Demnach ist der Aufwand für Heap Sort $\\mathcal{O}(n) + \\mathcal{O}(n \\log n) = \\mathcal{O}(n \\log n)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
