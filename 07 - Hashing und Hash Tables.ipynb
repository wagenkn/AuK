{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dictionary / Map\n",
    "\n",
    "Während Datensätze durch *Vergleiche* ihrer Schlüssel gesucht werden, geschieht dies beim **Hashing** (to hash = klein zerhacken) durch deren *Berechnung*. Es ist eine Methode zur dynamischen Verwaltung von Daten (value), die über einen Schlüssel (key) angesprochen werden. Ein Dictionary, auch Map genannt, ist ein Abstrakter Datentyp, der in der Informatik sehr wichtig ist und sehr häufig zum Einsatz kommt. Er ist in allen gängigen Programmiersprachen implementiert.\n",
    "\n",
    "Ein Dictionary besteht aus Schlüssel-Wert-Paaren (key-value pairs). Dabei wird von einem Schlüssel auf einen Wert abgebildet. Es gibt drei wesentliche Operationen, nämlich __insert__, __get__ und __remove__.\n",
    "\n",
    "__insert(key, value)__:\n",
    "\n",
    "Die Insert-Operation fügt ein Paar aus einem Schlüssel und einem Wert in die Datenstruktur ein. Sowohl Schlüssel, als auch der Wert, auf den abgebildet werden soll, können von jedem erdenklichen Datentyp sein.\n",
    "\n",
    "__get(key)__:\n",
    "\n",
    "Diese Operation gibt den Wert, auf den vom angegebenen Schlüssel abgebildet wird, zurück. Befindet sich kein Eintrag mit diesem Schlüssel im Dictionary, so wird __null__ zurückgegeben.\n",
    "\n",
    "__remove(key)__:\n",
    "\n",
    "Diese Operation entfernt einen Eintrag mit dem gegebenen Schlüssel aus dem Dictionary.\n",
    "\n",
    "Die genannten drei Operationen ließen sich mit balancierten Bäumen, beispielsweise einem AVL-Baum, implementieren. Jedoch liegt die Laufzeit für diese Operationen bei einem balancierten Baum in $\\mathcal{O}(\\log n)$. Ein Ziel dieses Kapitels ist es, eine Datenstruktur zu implementieren, die dies in konstanter Zeit schafft.\n",
    "\n",
    "# Direct Access Table\n",
    "\n",
    "Bei diesem Implementierungsversuch weist man, wie bei einem Array, der Datenstruktur einen festen Bereich im Speicher  zu. Nun kann man direkt über den Index auf jeden Slot zugreifen. Sind die Schlüssel nicht-negative ganze Zahlen, so kann man festlegen, dass der Schlüssel immer genau dem Index des Slots entspricht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "\n",
    "\n",
    "class DirectAccessTable:\n",
    "    def __init__(self):\n",
    "        self.table = []\n",
    "        for i in range(m):\n",
    "            self.table.append(None)\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        self.table[hash(key)] = value\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.table[hash(key)]\n",
    "\n",
    "    def remove(self, key):\n",
    "        self.table[hash(key)] = None\n",
    "\n",
    "\n",
    "# data type that only allows non-negative integers not exceeding slots size m\n",
    "class MyDataType:\n",
    "    def __init__(self, n):\n",
    "        if 0 <= n < m:\n",
    "            self.n = n\n",
    "        else:\n",
    "            raise Exception('Invalid value')\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.n\n",
    "\n",
    "\n",
    "direct_access_table = DirectAccessTable()\n",
    "a = MyDataType(1)\n",
    "b = MyDataType(125)\n",
    "c = MyDataType(7632)\n",
    "\n",
    "direct_access_table.insert(a, 'Hello')\n",
    "direct_access_table.insert(b, 'World')\n",
    "direct_access_table.insert(c, '!')\n",
    "\n",
    "print(direct_access_table.get(a))\n",
    "print(direct_access_table.get(b))\n",
    "print(direct_access_table.get(c))\n",
    "direct_access_table.remove(b)\n",
    "print(direct_access_table.get(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies wirft zwei Probleme auf:\n",
    "1. Zum einen möchte man eine Datenstruktur haben, bei welcher die Schlüssel von einem beliebigen Datentyp sind. (Es wurde als Bedingung angenommen, dass es sich um nicht-negative ganze Zahlen handelt). \n",
    "2. Zum anderen beträgt der Speicheraufwand $\\mathcal{O}(\\left| U \\right|)$. $U$ ist dabei das **Schlüsseluniversum**, d.h. die Menge aller möglichen Schlüssel. Für jeden (auch unverwendeten) Schlüssel wird Speicher reserviert. Dies wäre absolut unpraktikabel.\n",
    "\n",
    "Die meist viel kleinere **Schlüsselmenge** $K$ ($K \\subset U$) ist die Menge aller tatsächlich verwendeten Schlüssel, d.h. die, die sich zum betrachteten Zeitpunkt im Dictionary befinden.\n",
    "\n",
    "\n",
    "<img src=\"http://faculty.ycp.edu/~dbabcock/PastCourses/cs360/lectures/images/lecture11/directaddress.png\" width=\"400\">\n",
    "\n",
    "Die Anzahl $n$ der Elemente, die sich momentan in der Datenstruktur befinden, ergibt sich aus der Kardinalität der Schlüsselmenge $\\left| K \\right|$ .\n",
    "\n",
    "# Hash Table\n",
    "\n",
    "Eine Hash Table bzw. Hash Map ist eine Implementation des ADT Dictionary. Dabei wird auch per direkten Slotzugriff, wie bei der Direct Access Table, vorgegangen. Jedoch gibt es eine feste Anzahl $m$ an Slots, wobei gilt $m \\ll \\left| U \\right|$. Nun wird eine Hashfunktion $h: U \\to \\{0, 1, \\dotsc, m-1\\}$ benötigt, die vom Schlüsseluniversum auf einen der Slots $\\{0, 1, \\dotsc, m-1\\}$ abbildet. Aus diesem Größenvergleich folgt, dass eine Hashfunktion im Allgemeinen nicht injektiv ist. Eine gute Hashfunktion ist surjektiv, damit alle Schlüssel vorkommen können. Eine einfache Funktion ist beispielsweise $h: k \\mapsto k \\bmod m$.\n",
    "\n",
    "Somit wurde der Speicheraufwand deutlich reduziert.\n",
    "\n",
    "Um das Problem, dass es sich bei den Schlüsseln um etwas anderes als nicht-negative Integers, z.B. Strings, handeln kann, zu lösen, wird eine sogenannte pre-hash Funktion benötigt. Diese ist eine Funktion, die vom Schlüsseluniversum auf eine nicht-negative ganze Zahl abbildet. Theoretisch betrachtet ist dies immer möglich, da alles, was in einem Computer dargestellt wird, diskret und endlich ist. Schließlich könnte man die Bits, durch welche das entsprechende Datum dargestellt wird, als nicht-negativen Integer auffassen und dies als den pre-hash-Wert nehmen. Dies würde jedoch mitunter zu sehr großen Zahlen führen, weshalb man in der Praxis meist bessere pre-hash-Funktionen verwendet. Hat man beispielsweise einen String mit Zeichen aus <tt>a-z</tt>, so könnte man diese Zeichenkette als Zahl im Stellenwertsystem mit der Basis $26$ auffassen.\n",
    "\n",
    "__Beispiel__:\n",
    "\n",
    "$h('adf') = 0 \\cdot 26^2 + 3 \\cdot 26 + 5 \\cdot 1 = 83$\n",
    "\n",
    "Nun kann man mit dem \"geprehashten\" Wert, der ein nicht-negativer Integer ist, so umgehen, als wäre dieser der eigentliche Schlüssel. \n",
    "\n",
    "In der Programmiersprache Java beispielsweise findet dieses Pre-Hashing durch die `hashCode()`-Methode, die jede Klasse implementiert, statt.\n",
    "\n",
    "## Kollisionen\n",
    "\n",
    "Durch die Tatsache, dass $h$ wegen $m < \\left| U \\right|$ im Allgemeinen nicht injektiv ist, entsteht ein neues Problem, nämlich Kollisionen.\n",
    "\n",
    "Eine **Kollision** unter der Hashfunktion $h$ tritt auf, wenn für $k_i, k_j \\in K$ mit $i \\neq j$ gilt $h(k_i) = h(k_j)$.\n",
    "\n",
    "<img src=\"http://www.cs.fsu.edu/~burmeste/slideshow/images_content/figure12_2.gif\" width=\"450\">\n",
    "\n",
    "Eine Kollision ergibt sich, wenn zwei oder mehrere unterschiedliche Schlüssel den gleichen Hash-Wert haben. Dies hat zur Folge, dass sie sich den gleichen Slot in der Hash Map teilen müssten. Um dieses Problem zu behandeln, gibt es mehrere Verfahren. Im Folgenden werden **Hashing with Chaining** und **Open Addressing** vorgestellt.\n",
    "\n",
    "## Hashing with Chaining\n",
    "\n",
    "Bei __Hashing with Chaining__ wird in einem Slot der Hash Table anstatt eines Wertes eine Linked List von Schlüssel-Wert-Paaren gespeichert. Kommt es beim Einfügen zu einer Kollision, so fügt man das Schlüssel-Wert-Paar ans Ende dieser Liste ein. Möchte man nach einem Schlüssel suchen, so muss man durch die Liste an dem entsprechenden Slot iterieren. \n",
    "\n",
    "<img src=\"http://www.cs.fsu.edu/~burmeste/slideshow/images_content/figure12_3.gif\" width=\"450\">\n",
    "\n",
    "Für die Implementation nutzen wir die SinglyLinkedList, die bereits in Kapitel 3 implementiert wurde. Der Einfachkeit halber, wird auf die Implementation der __remove__-Methode verzichtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing\n",
      "with\n",
      "Chaining\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "        self.next = None\n",
    "\n",
    "    def add(self, value, index):\n",
    "        if index > 1 and self.next is not None:\n",
    "            return self.next.add(value, index - 1)\n",
    "        elif index == 1:\n",
    "            new_node = Node()\n",
    "            new_node.value = value\n",
    "            new_node.next = self.next\n",
    "            self.next = new_node\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class SinglyLinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = Node()\n",
    "        self.length = 0\n",
    "\n",
    "    def add(self, value, index=None):\n",
    "        if index is None:\n",
    "            index = self.length\n",
    "        if index == 0:\n",
    "            new_node = Node()\n",
    "            new_node.value = value\n",
    "            new_node.next = self.head\n",
    "            self.head = new_node\n",
    "            self.length += 1\n",
    "        elif 0 < index <= self.length:\n",
    "            if self.head.add(value, index):\n",
    "                self.length += 1\n",
    "\n",
    "\n",
    "class HashTable:\n",
    "    def __init__(self):\n",
    "        self.table = []\n",
    "        for i in range(m):\n",
    "            self.table.append(SinglyLinkedList())\n",
    "\n",
    "    # hash function of the hash table, using a really simple one here\n",
    "    @staticmethod\n",
    "    def __hash(key):\n",
    "        return hash(key) % m\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        self.table[HashTable.__hash(key)].add((key, value))\n",
    "        \n",
    "    def get(self, key):\n",
    "        node = self.table[HashTable.__hash(key)].head\n",
    "        while node is not None:\n",
    "            if node.value is not None and node.value[0] == key:\n",
    "                return node.value[1]\n",
    "            node = node.next\n",
    "        return None\n",
    "    \n",
    "    \n",
    "hash_table = HashTable()\n",
    "\n",
    "# now our hash table allows us to use any data type as key, in this case a string\n",
    "hash_table.insert('a', 'Hashing')\n",
    "hash_table.insert('b', 'Chaining')\n",
    "hash_table.insert('c', 'with')\n",
    "\n",
    "print(hash_table.get('a'))\n",
    "print(hash_table.get('c'))\n",
    "print(hash_table.get('b'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handelt es sich um eine sehr schlechte Hashfunktion, bei der es viele Kollisionen gibt, so kann es passieren, dass (fast) alle Schlüssel den gleichen Hash-Wert haben und somit eine Linked List mit der Länge $\\mathcal{O}(n)$ bilden. $n$ ist dabei die Anzahl der Elemente in der Datenstruktur, $n = \\left| K \\right|$. Die worst-case Komplexität liegt somit für alle Operationen in $\\mathcal{O}(n)$. Für gute Hashfunktionen tritt dieser worst-case jedoch mit einer sehr geringen Wahrscheinlichkeit ein. Man kann $\\mathcal{O}(\\log n)$ im worst-case erreichen, indem man statt Linked Lists ballancierte Bäume verwendet.\n",
    "\n",
    "## Simple Uniform Hashing\n",
    "\n",
    "Man spricht von Simple Uniform Hashing, wenn die Hashfunktion $h$ die Schlüsselmenge $K$ uniform zufällig auf die Werte $\\{0, 1, \\dotsc, m-1\\}$ verteilt. *Uniform zufällig* bedeutet, dass jeder Hash-Wert gleich wahrscheinlich auftreten kann, so als ob man den Hash-Wert in einem Zufallsexperiment bestimmt. \n",
    "\n",
    "Die Annahme, dass die Verteilung der Hash-Werte uniform ist, tritt in der Praxis nicht ein, jedoch hilft diese Annahme um zu verstehen, warum Operationen in einer Hash Map eine erwartete Laufzeit von $\\mathcal{O}(1)$ haben:\n",
    "\n",
    "Der Erwartungswert für die Anzahl der Elemente in einem Slot unter der Annahme von Uniform Hashing ist $n \\cdot \\frac{1}{m} = \\frac{n}{m}$. Nehmen wir an, dass $n \\in \\mathcal{O}(m)$, also die Anzahl der Elemente $n$ maximal ein Vielfaches (Konstante als Faktor) von der Anzahl der Slots $m$ ist, so befinden sich vorraussichtlich $\\leqslant \\frac{c \\cdot m}{m} = c$ Elemente in einer Liste. Da $c$ eine Konstante ist, befinden sich lediglich $\\mathcal{O}(1)$ Elemente in einer Liste.\n",
    "<!-- div style=\"text-align: right; font-size: 24px;\">&#9633;</div -->\n",
    "\n",
    "## Table Doubling\n",
    "\n",
    "Das Problem ist, dass $n$ nicht vorhersagbar ist; schließlich können ständig Werte in das Dictionary eingefügt und entfernt werden. Ist $n$ nämlich viel größer als $m$, so sind die Listen, durch die iteriert werden muss, sehr lang und somit wäre die Datenstruktur ineffizient. Wie kann man also sicherstellen, dass $n \\in \\mathcal{O}(m)$ immer gilt? Hierfür wird eine Technik angewandt, die bereits von dynamischen Arrays bekannt ist, nämlich das Verdoppeln der Größe, sobald die Anzahl der Elemente zu groß wird. Man spricht hier von Table Doubling.\n",
    "\n",
    "Table Doubling wird durchgeführt, sobald $n > m$. Dabei wird die Anzahl der Slots $m$ verdoppelt. Die Anzahl der Slots nach Table Doubling ist dann $m'=2m$. Um die Elemente nun auf $m'$ Slots zu verteilen, ist eine neue Hashfunktion nötig. Handelt es sich zunächst beispielsweise um die sehr einfache Hashfunktion $h: x \\mapsto x \\bmod m$, so wird sie entsprechend zu $h': x \\mapsto x \\bmod m'$ abgeändert. Die bereits eingefügten Elemente werden nun nach der neuen Hashfunktion $h'$ neu eingefügt, man spricht hier von Rehashing. Die Kosten für die ganze Table Doubling Operation betragen $\\mathcal{O}(n)$. Analog wie für dynamische Arrays kann man aber zeigen, dass die Kosten amortisiert weiterhin lediglich $\\mathcal{O}(1)$ betragen.\n",
    "\n",
    "Durch Table Doubling ist sichergestellt, dass $n \\in \\mathcal{O}(m)$ immer gilt und somit die erwartete Laufzeit mit Uniform Hashing $\\mathcal{O}(1)$ beträgt.\n",
    "\n",
    "## Open Addressing\n",
    "\n",
    "Open Addressing ist eine andere Variante, um eine Hash Map zu implementieren. Dabei gibt es keine Verkettung, sondern es wird immer maximal ein Element in einem Slot gespeichert. Somit muss $m \\geqslant n$ gelten. \n",
    "\n",
    "__Insert__\n",
    "\n",
    "Möchte man ein Element einfügen, das einen Hash-Wert hat, welcher einem Slot entspricht, der schon belegt ist, so berechnet man einen neuen Hash und fügt das Element an dieser Stelle ein, falls dieser Slot frei ist. Die Hashfunktion bei Open Addressing ist also eine spezielle Hashfunktion, die nicht nur den Schlüssel als Parameter nimmt, sondern auch die Zahl des Versuches, um den es sich handelt. Die Hashfunktion $h$ ist also von der Form \n",
    "\n",
    "$$\n",
    "h: U \\times \\{0, 1, \\dotsc, m-1\\} \\to \\{0, 1, \\dotsc, m-1\\}.\n",
    "$$\n",
    "\n",
    "Eine entscheidende Anforderung an solch eine Hashfunktion ist, dass der Vektor \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}h(k, 0) & h(k, 1) & \\cdots & h(k, m-1) \\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "mit $k\\in U$ eine Permutation des Vektors \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}0 & 1 & \\cdots & m-1 \\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "ist.\n",
    "\n",
    "Dies bedeutet, dass man nach $m$ Versuchen jeden der $m$ Slots genau einmal \"durchprobiert\" hat. Unter der Bedingung $m \\geqslant n$, findet man demnach in jedem Fall einen freien Slot.\n",
    "\n",
    "__Search__\n",
    "\n",
    "Um einen Schlüssel zu suchen, wendet man die Hashfunktion $h$ ebenfalls mit entsprechendem Versuchszähler an. Man beginnt mit der Versuchszahl 0. Hat man Glück und findet den Schlüssel an dem entsprechenden Slot, so kann man aufhören und hat das Element gefunden. Handelt es sich um einen __null__ Wert, so kann man auch aufhören, mit der Erkenntnis, dass sich der gesuchte Schlüssel nicht in der Hash Map befindet. Findet man an dem entsprechenden Slot, einen anderen Schlüssel, so muss man einen neuen Hash-Wert mit inkrementierten Versuchszähler berechnen. \n",
    "\n",
    "Dass man bei einem __null__ Wert aufhören kann, liegt daran, dass wenn der gesuchte Schlüssel sich in der Datenstruktur befände, man ihn genau an dieser Stelle eingefügt hätte. Da er sich aber nicht dort befindet, befindet er sich auch nirgendswo anders in der Hash Map.\n",
    "\n",
    "__Remove__\n",
    "\n",
    "Das Entfernen von Schlüsseln aus einer Hash Table mit Open Addressing stellt sich etwas problematisch dar. Entfernt man nämlich ein Element, so funktioniert die Suche nicht mehr, da die Probiersequenz, die zum eigentlichen Schlüssel führen soll, nun durch ein gelöschtes Element unterbrochen wurde und der Suchalgorithmus \"denken\" würde, der Schlüssel befindet sich nicht in der Hash Table. Aus diesem Grund darf man das Element nicht einfach entfernen, sondern man muss einen __deleted__-Marker einführen, der signalisiert, dass man weitersuchen muss, da sich hier mal ein Schlüssel befand. Der Suchalgorithmus bleibt prinzipiell der gleiche. Trifft man auf einen __null__-Wert, so kann man aufhören. Hat man den gesuchten Schlüssel gefunden, so kann man ebenfalls aufhören. Bei jedem anderen Wert - __deleted__-Marker eingeschlossen - muss man mit inkrementierten Versuchszähler weiterprobieren.\n",
    "\n",
    "Nun stellt sich die Frage, wie man eine Hashfunktion entwickelt, die den Anforderungen von Open Addressing entspricht. Sie muss zusätzlich eine Versuchszahl als Parameter nehmen und alle $m$ Slots genau einmal zurückgeben.\n",
    "\n",
    "### Linear Probing\n",
    "\n",
    "Die naheliegendste Variante (lineares Sondieren) ist es, einfach beim nächsten Versuch um $i$ Slot(s) weiterzugehen, um auf einen freien Platz zum Schlüsseleintrag zu treffen. Also entwirft man folgende Hashfunktion, wobei $h'$ eine gewöhnliche einstellige Hashfunktion vom Typ $h':U \\mapsto \\{0, 1, \\dotsc, m-1\\}$ ist:\n",
    "\n",
    "$$\n",
    "h(k, i) = (h'(k) + i)\\bmod m\n",
    "$$\n",
    "\n",
    "Diese Hashfunktion ist einfach, aber leider schlecht. Hat sich etwa ein *Cluster* in der Hash Map gebildet, d.h. ein Zustand, bei dem viele Slots unmittelbar hintereinander belegt sind, so muss man definitiv das komplette Cluster durchiterieren, bis man einen freien Platz findet. Zudem hat man jetzt dieses Cluster auch noch um 1 vergrößert. Je größer ein Cluster ist, desto größer ist auch die Wahrscheinlichkeit es beim ersten Versuch zu treffen. Genau genommen $\\frac{k}{m}$, wenn $k$ die Größe des Clusters ist und $m$ die Anzahl der Slots in der Hash Map.\n",
    "\n",
    "### Double Hashing\n",
    "\n",
    "Double Hashing verwendet zwei zufällig ausgewählte Hashfunktionen $h_1$ und $h_2$. Die Hashfunktion $h$ wird folgendermaßen definiert:\n",
    "\n",
    "$$\n",
    "h(k, i) = \\left( h_1(k) + i h_2(k) \\right) \\bmod m\n",
    "$$\n",
    "\n",
    "Damit sichergestellt ist, dass die Hashfunktion die erforderte Permutation erzeugt, müssen alle Werte von $h_2(k)$ und $m$ relativ prim, also teilerfremd, sein.\n",
    "\n",
    "Diese Hashfunktion erzeugt eine wesentlich durchmischtere Verteilung der Hash-Werte, wodurch sich (wahrscheinlich) keine Cluster bilden und die somit besser geeignet ist.\n",
    "\n",
    "## Hashfunktionen\n",
    "\n",
    "Bisher wurde geklärt, wie man eine Hash Table implementiert. Nun ist zu klären, wie man eine passende Hashfunktion $h$, die vom Schlüsseluniversum auf $\\{0, 1, \\dotsc, m-1 \\}$ abbildet, konstruiert. Im Folgenden werden drei Methoden vorgestellt.\n",
    "\n",
    "### Divisionsmethode\n",
    "\n",
    "$$\n",
    "h(k) = k \\bmod m\n",
    "$$\n",
    "\n",
    "Diese Hashfunktion ist sehr einfach, jedoch nicht sonderlich gut. Ist $m$ eine Zweierpotenz, was bei Table Doubling immer der Fall ist, so teilt es sich unter Umständen sehr viele Teiler mit dem Schlüssel, was dazu führt, dass bestimmte Hash-Werte unter der Menge $\\{0, 1, \\dotsc, m-1 \\}$ besonders häufig vorkommen. Dies würde zu vielen Kollisionen führen, was die Datenstruktur ineffizient macht.\n",
    "\n",
    "### Multiplikationsmethode\n",
    "\n",
    "$$\n",
    "h(k) = \\left\\lfloor \\frac{A \\cdot k \\bmod 2^w}{2^{w-r}} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "<img src=\"http://staff.ustc.edu.cn/~csli/graduate/algorithms/book6/229_a.gif\" width=\"350\">\n",
    "\n",
    "Diese Hashfunktion multipliziert den Schlüssel mit einem Faktor $A$. $w$ ist die Wortbreite des Systems. $A$ ist aus der Menge $\\{0, 1, \\dotsc , 2^{w-1} \\}$ zu wählen. Das Ergebnis der Multiplikation $A \\cdot k$ besteht aus $2w$ Bits. Anschließend wird $\\bmod 2^w$ gebildet, was dazu führt, dass nur die rechten Hälfte, also die rechten $w$ Bits weiter betrachtet werden. Danach wird durch $2^{w-r}$ geteilt, was einem Bitshift von $w-r$ Bits entspricht. Als Ergebnis bleibt ein Wert mit $r$ Bits übrig. $r$ ist dabei so zu wählen, dass gilt $m=2^r$.\n",
    "\n",
    "Diese Hashfunktion ist besser, da hier ein Durchmischen stattfindet und somit die Hashwerte besser, also gleichmäßiger, verteilt sind.\n",
    "\n",
    "### Universelles Hashing\n",
    "\n",
    "Eine Möglichkeit für universelles Hashing ist die Klasse folgender Hashfunktionen:\n",
    "\n",
    "$$\n",
    "h(k) = ((a \\cdot k + b) \\bmod p) \\bmod m\n",
    "$$\n",
    "\n",
    "$p$ ist dabei eine Primzahl, für die gilt $p \\geqslant m$. Wird eine Hashfunktion benötigt, so werden $a$ und $b$ zufällig aus der Menge $\\{0, 1, \\dotsc, p-1\\}$ gewählt. Damit die Hash-Werte uniform auf $\\{0, 1, \\dotsc, m-1\\}$ verteilt werden, müssen $p$ und $m$ teilerfremd sein. Durch die Bedingung, dass $p$ eine Primzahl ist, ist dies gegeben.\n",
    "\n",
    "Da $a$ und $b$ zufällig gewählt werden, handelt es sich hierbei um eine Menge bzw. Klasse $\\mathcal{H}$ von Hashfunktionen, die aus $p^2$ Funktionen besteht. Die hier vorgestellte Klasse von Hashfunktionen ist $\\approx 1$-universell.\n",
    "\n",
    "Eine Klasse $\\mathcal{H}$ von Hashfunktionen ist **$c$-universell**, wenn für alle $x, y \\in U$ mit $x \\neq y$ mit zufällig ausgewählten $h \\in \\mathcal{H}$ gilt, dass $Pr(h(x) = h(y)) \\leqslant c \\cdot \\frac{1}{m}$.\n",
    "\n",
    "Ist die Klasse $\\mathcal{H}$ 1-universell, so ist bei zufällig ausgewähltem $h$ die Wahrscheinlichkeit einer Kollision $\\leqslant \\frac{1}{m}$. Anders fomulliert gibt es nicht mehr als $c \\cdot \\frac{\\left| \\mathcal{H} \\right|}{m}$ Hashfunktionen, die für ein Schlüsselpaar den gleichen Hash-Wert liefern.\n",
    "\n",
    "Auf den Beweis, dass die genannte Klasse von Hashfunktionen universell ist, wird verzichtet.\n",
    "\n",
    "# String Matching\n",
    "\n",
    "String Matching ist ein Problem, bei dem es darum geht, in einem String einen bestimmten Substring zu finden. Dies ist ein Problem, welches in der Praxis sehr häufig auftritt, beispielsweise in Texteditoren bei der Suche mit CTRL+F oder beim Linux Tool `grep`. In beiden Beispielen geht es darum, in einer sehr großen Datei, also einem String (Zeichenkette), einen bestimmten Substring zu finden, bzw. herauszufinden, ob dieser überhaupt vorkommt.\n",
    "\n",
    "Ein naiver Ansatz ist es, jede Position der Zeichenkette der Länge $n$ als potenzielle Startposition des $k$-langen Substrings anzusehen und durch Zeichenvergleich ($k$ Zeichen) zu prüfen. $n$ ist die Länge des Strings und $k$ die Länge des Substrings. Dieser Algorithmus hat einen Zeitaufwand von $\\mathcal{O}(nk)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "def string_matching(str, substr):\n",
    "    for i in range(len(str) - len(substr) + 1):\n",
    "        match = True\n",
    "        for j in range(len(substr)):\n",
    "            if str[i + j] != substr[j]:\n",
    "                match = False\n",
    "        if match:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "\n",
    "print(string_matching('Just using a naive string matching approach', 'string matching'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karp-Rabin Algorithmus\n",
    "\n",
    "Der Karp-Rabin Algorithmus ermöglicht es, das String Matching Problem in einer besseren Laufzeit als $\\mathcal{O}(nk)$ zu lösen. Dabei wird das Prinzip von Hashes genutzt. Anstatt aber beim Durchiterieren jedesmal einen neuen Hash zu berechnen, nutzt man die Tatsache, dass sich beim Verschieben des Schiebefensters, welcher den Substring, der gerade untersucht wird, darstellt, sich nur das erste und letzte Zeichen ändern und die Mitte des Substrings gleich bleibt. Konstruiert man die Hashfunktion so, dass man den String als Zahl mit der Basis, die der Größe des Alphabets entspricht, auffasst, so kann man den Hash nach Entfernen des ersten Zeichens und Anfügen eines neuen Zeichens, mit Hilfe von einfachen Rechenoperationen in konstanter Zeit berechnen.\n",
    "\n",
    "__Beispiel für einen Hash mit Basis 26: __\n",
    "$h('hash') = 7 \\cdot 26^3 + 0 \\cdot 26^2 + 18 \\cdot 26 + 7 \\cdot 1 = 123507$\n",
    "\n",
    "Fügt man jetzt z.B. das Zeichen x hinzu, so müsste man zunächst die Zahl $(7,0,18,7)_{26}$ mit der Basis multiplizieren, also erhält man $(7,0,18,7,0)_{26}$. Diese Operation ist äquivalent zur Multiplikation mit 10 im Dezimalsystem. Nun addiert man den Wert des neuen Zeichens, nämlich 23 und erhält $(7,0,18,7,23)_{26}$.\n",
    "\n",
    "Nun benötigt man eine Rechenoperation, mit der man das erste Zeichen entfernen kann. Man muss also die erste Ziffer abschneiden. Dies führt man durch, indem man die Hash-Zahl modulo $\\text{Basis}^{\\text{Länge des Strings - 1}}$ nimmt. In diesem Fall $\\bmod 26^4$ und man erhält $(0,18,7,23)_{26}$.\n",
    "\n",
    "Mit Hilfe dieser Arithmetik kann man nun eine Datenstruktur names **Rolling Hash** implementieren, die in konstanter Zeit ein Zeichen anfügt, in konstanter Zeit das erste Zeichen entfernt und in konstanter Zeit den aktuellen Hash-Wert zurückgibt.\n",
    "\n",
    "Der Algorithmus iteriert nun durch $n$ Zeichen des Strings und vergleicht den Rolling Hash-Wert *des Substrings ab dem entsprechenden Index* mit dem Rolling Hash-Wert *des gesuchten Substrings*, der im Voraus berechnet wurde. Da die Basis nicht der Größe des Alphabets entspricht, dies auch für UNICODE-Zeichen nicht praktikabel wäre, kommt es zu Kollisionen, d.h. unterschiedliche Strings können den gleichen Hash-Wert haben. Dadurch muss man im positiven Fall, d.h. die Hash-Werte stimmen überein, beide Strings noch Zeichen für Zeichen überprüfen. Da aber Kollisionen sehr selten sind, hat das keinen bedeutenden Einfluss auf die erwartete Laufzeit des Algorithmus.\n",
    "\n",
    "Die erwartete Laufzeit des Algorithmus beträgt $\\mathcal{O}(n+k)$, da man zunächst einen Aufwand von $k$ hat, um den Rolling Hash des gesuchten Substrings zu berechnen und anschließend $n$-mal (erwarteten) konstanten Aufwand hat, um den Rolling Hash mit den __append__ und __skip__ Operationen anzupassen und ihn entsprechend abzugleichen. Dieser Algorithmus ist im Vergleich zum naiven Brute-Force Ansatz besonders effizient, wenn $k$, also die Länge des Substrings, groß ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "class RollingHash:\n",
    "    def __init__(self):\n",
    "        self.string = ''\n",
    "        self.base = 256\n",
    "        self.hash = 0\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.hash\n",
    "\n",
    "    def append(self, c):\n",
    "        self.hash *= self.base\n",
    "        self.hash += ord(c) % self.base\n",
    "        self.string += c\n",
    "\n",
    "    def skip(self):\n",
    "        if len(self.string) > 0:\n",
    "            self.string = self.string[1:]\n",
    "            self.hash %= self.base ** len(self.string)\n",
    "        else:\n",
    "            raise Exception('string is empty')\n",
    "\n",
    "\n",
    "def karp_rabin(str, substr):\n",
    "    if len(substr) <= len(str):\n",
    "        rolling_hash_substr = RollingHash()\n",
    "        rolling_hash_str = RollingHash()\n",
    "        for i in range(len(substr)):\n",
    "            rolling_hash_substr.append(substr[i])\n",
    "            rolling_hash_str.append(str[i])\n",
    "        hash_value_substr = hash(rolling_hash_substr)\n",
    "        if hash_value_substr == hash(rolling_hash_str):\n",
    "            if rolling_hash_str.string == substr:\n",
    "                return 0\n",
    "        for i in range(len(substr), len(str)):\n",
    "            rolling_hash_str.skip()\n",
    "            rolling_hash_str.append(str[i])\n",
    "            if hash_value_substr == hash(rolling_hash_str):\n",
    "                if rolling_hash_str.string == substr:\n",
    "                    return i - len(substr) + 1\n",
    "    return None\n",
    "\n",
    "\n",
    "print(karp_rabin('Karp Rabin is awesome.', 'Rabin'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
