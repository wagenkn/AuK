{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation: Anwendungsfall \"Wählerliste\"\n",
    "\n",
    "Bei Wahlverfahren wird zuerst festgestellt, ob ein (mit Personalausweis identifizierbarer) Wahlbenachrichtigter tatsächlich *wahlberechtigt* ist. Hierfür wird geprüft, \n",
    "    1. ob der Name dieser Person im Wählerverzeichnis steht und \n",
    "    2. ob diese Person noch nicht gewählt hat. \n",
    "Ist das der Fall, schließt sich der entsprechende Wahlvorgang an.\n",
    "\n",
    "Die Wahlhelfer könnten für diese Prüfung das Verfahren der *linearen Suche* anwenden: Sie beginnen beim ersten Namenseintrag im Wählerverzeichnis und vergleichen diesen Namen mit dem der zu überprüfenden Person. Markierte Listenelemente, d.h. die Namen der Bürger, die ihre Stimmen bereits abgegeben haben, werden nicht betrachtet. Im ungünstigsten Fall steht der gesuchte Name am Ende der Liste mit $n$ Elementen, sodass sich ein Aufwand von $\\mathcal{O}(n)$ ergibt. Nicht zu unterschätzen ist der Aufwand $K$ für jeweils einen Namensvergleich, z.B. für Sabine Leutheusser-Schnarrenberger (deutsche Politikerin) oder für zu scannende Passbilder. $K$ lässt sich durch eine Konstante nach oben abschätzen, sodass es trotz $\\mathcal{O}(n\\cdot K)$ bei $\\mathcal{O}(n)$ bleibt.\n",
    "\n",
    "Ein *linearer Aufwand* im schlechtesten Fall ist ein sehr guter Wert, führt aber für große $n$ dennoch zu erheblichen Wartezeiten. Er lässt sich jedoch verringern, wenn das Wählerverzeichnis nach Namen sortiert vorliegt. Der dafür erforderliche Sortieraufwand fällt genau einmal an, nämlich vor dem o.g. Prüfprozess. Verwendet man anschließend die sehr effiziente *binäre Suche*, so ergibt sich ein Aufwand in $\\mathcal{O}(\\log{}n)$.\n",
    "\n",
    "Eine noch bessere Effizienz kann man nur erzielen, wenn man sich grundsätzlich vom Suchprozess verabschiedet: Wir stellen uns vor, dass jemand alle Wählerinnen und Wähler kennt und über deren Teilnahme am Wahlvorgang Kenntnis besitzt. Diese Person brauchen wir dann nur zu fragen, ob der betreffende Bürger wahlberechtigt ist oder nicht. Der dafür erforderliche Aufwand ist *konstant*, d.h. unabhängig von $n$: $\\mathcal{O}(1)$.\n",
    "\n",
    "Anstelle die Position eines Listenelements zu *suchen*, wird die zugehörige Adresse *berechnet*. Statt einer Liste verwenden wir dafür eine sog. *Hashtabelle* (Hashmap, dictionary, assoziative Datenfelder). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dictionary\n",
    "\n",
    "Während Datensätze durch *Vergleiche* ihrer Schlüssel gesucht werden, geschieht dies beim **Hashing** (to hash = klein zerhacken) durch *Berechnung* der Adressen (Indizes) der Datensätze in einem Feld. Es ist eine Methode zur dynamischen Verwaltung von Daten (*value*), die über einen Schlüssel (*key*) angesprochen werden. Die drei Dictionary-Operationen (Einfügen, Suchen, Löschen) werden mit *Hashtabellen* (Hashtable, Hashmap) implementiert. \n",
    "\n",
    "Ein Dictionary (Wörterbuch) besteht aus Schlüssel-Wert-Paaren (key-value pairs). Um festzustellen, ob ein bestimmter Schlüssel in der Hashmap enthalten ist oder nicht, ist eine *Hashfunktion* $h$ erforderlich: Sie nimmt z.B. eine Zeichenkette (key) und liefert eine (natürliche) Zahl, z.B. $h($\"Sabine Leutheusser-Schnarrenberger\"$)=27535$. Diese Zahl fungiert als *Index eines Feldes* (Array), das den zugehörigen Wert enthält, z.B. \"ist wahlberechtigt\" bzw. \"hat schon gewählt\". \n",
    "\n",
    "Ein anderes sehr praxisrelevantes Beispiel für Hashing ist die Abbildung von Webadressen (key) auf IP-Adressen (value), wie z.B. `h(google.com)=j` und `IP-Array[j]=74.125.239.133`. Man nennt diesen Vorgang *IP-Adressauflösung*.\n",
    "\n",
    "Wir ahnen schon, dass die Entwicklung einer geeigneten Hashfunktion eine besondere Herausforderung darstellt.\n",
    "\n",
    "Ein Dictionary ist ein *Abstrakter Datentyp* (ADT), der in der Informatik sehr wichtig ist und sehr häufig zum Einsatz kommt. Er ist in allen gängigen Programmiersprachen implementiert. Es gibt drei wesentliche Operationen, nämlich __insert__, __get__ und __remove__. (Stillschweigend setzt man die Existenz einer Initialisierungsoperation voraus.)\n",
    "\n",
    "Schlüssel und Werte können von jedem erdenklichen Datentyp sein.\n",
    "\n",
    "__insert(key, value)__:\n",
    "\n",
    "Die Insert-Operation fügt ein Paar aus einem Schlüssel und einem Wert in die Datenstruktur ein. \n",
    "\n",
    "__get(key)__:\n",
    "\n",
    "Diese Operation gibt den vom angegebenen Schlüssel adressierten Wert zurück. Befindet sich kein Eintrag mit diesem Schlüssel im Dictionary, so wird __null__ zurückgegeben.\n",
    "\n",
    "__remove(key)__:\n",
    "\n",
    "Diese Operation entfernt einen Eintrag mit dem gegebenen Schlüssel aus dem Dictionary.\n",
    "\n",
    "Die genannten drei Operationen ließen sich mit balancierten Bäumen, beispielsweise mit AVL-Bäumen, implementieren. Jedoch liegt die Laufzeit für diese Operationen bei einem balancierten Baum in $\\mathcal{O}(\\log n)$. Ein Ziel dieses Kapitels ist es, eine Datenstruktur zu implementieren, die dies in konstanter Zeit schafft. Da Dictionarys auch in Python (als `dict`) implementiert sind, können wir am Ende unsere Implementierung mit der eingebauten Datenstruktur experimentell vergleichen.\n",
    "\n",
    "## Direct Access Table\n",
    "\n",
    "Bei dem folgenden Implementierungsversuch weist man, wie bei einem Array, der Datenstruktur einen festen Bereich im Speicher zu. Dann kann man direkt über den *Index* auf jeden Slot (Feldelement) zugreifen. Sind die Schlüssel nicht-negative ganze Zahlen, so kann man - wie für die folgende Implementierung - festlegen, dass sich jeder Index des Slots direkt aus dem Schlüssel identisch ergibt, d.h. die Hashfunktion ist $h:\\mathbb{N}\\mapsto\\mathbb{N}$ mit $h(n)=n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n",
      "!\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = 10000  # set m = 1000\n",
    "\n",
    "\n",
    "class DirectAccessTable:\n",
    "    def __init__(self):\n",
    "        self.table = []\n",
    "        for i in range(m):\n",
    "            self.table.append(None)\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        self.table[hash(key)] = value\n",
    "\n",
    "    def get(self, key):\n",
    "        return self.table[hash(key)]\n",
    "\n",
    "    def remove(self, key):\n",
    "        self.table[hash(key)] = None\n",
    "\n",
    "\n",
    "# data type that only allows non-negative integers not exceeding slots size m\n",
    "class MyDataType:\n",
    "    def __init__(self, n):\n",
    "        if 0 <= n < m:\n",
    "            self.n = n\n",
    "        else:\n",
    "            raise Exception('Invalid value')\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.n\n",
    "\n",
    "\n",
    "direct_access_table = DirectAccessTable()\n",
    "a = MyDataType(1)\n",
    "b = MyDataType(125)\n",
    "c = MyDataType(7632)\n",
    "\n",
    "direct_access_table.insert(a, 'Hello')\n",
    "direct_access_table.insert(b, 'World')\n",
    "direct_access_table.insert(c, '!')\n",
    "\n",
    "print(direct_access_table.get(a))\n",
    "print(direct_access_table.get(b))\n",
    "print(direct_access_table.get(c))\n",
    "direct_access_table.remove(b)\n",
    "print(direct_access_table.get(b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die oben für $h$ verwendete identische Funktion gilt natürlich nur in diesem speziellen Fall, da die Schlüssel natürliche Zahlen sind. Von einer Hashfunktion $h:K\\mapsto \\{0,1,2,\\ldots,m-1\\}$ erwarten wir, dass sie folgende Eigenschaften erfüllt:\n",
    "\n",
    "1. Im Allgemeinen sollen Schlüssel beliebigen Datentyps verwendet werden können. \n",
    "\n",
    "2. Die $\\left| K \\right|$ zum Betrachtungszeitpunkt *tatsächlich vorwendeten* Schlüssel, d.h. die Elemente der **Schlüsselmenge** $K\\subset U$ sollen möglichst zufällig und gleichmäßig über die Indizes $\\{0,1,2,\\ldots,m-1\\}$ mit $m \\ll \\left| U \\right|$ gestreut werden. ($K$ ist im Allgemeinen nicht bekannt.) $U$ ist dabei das **Schlüsseluniversum**, d.h. die Menge aller *möglichen* Schlüssel. Für jeden (auch unbenutzten) Schlüssel wird Speicher insgesamt in $\\mathcal{O}(\\left| U \\right|)$ reserviert und gegebenfalls verschwendet.\n",
    "<img src=\"http://faculty.ycp.edu/~dbabcock/PastCourses/cs360/lectures/images/lecture11/directaddress.png\" width=\"400\">\n",
    "\n",
    "3. $h$ soll möglichst \"einfach\" und \"schnell\" berechenbar sein.\n",
    "\n",
    "Die naheliegende Hoffnung, dass $h$ *injektiv* ist, d.h. dass zwei verschiedene, tatsächlich verwendete Schlüssel $s_1, s_2\\in K$ mit $s_1\\neq s_2$ unterschiedliche Hashwerte $h(s_1)\\neq h(s_2)$ haben, kann im Allgemeinen nicht aufrecht erhalten werden.\n",
    "\n",
    "Eine gute Hashfunktion ist *surjektiv*, damit alle Indizes vorkommen können.\n",
    "\n",
    "\n",
    "## Hashtable\n",
    "\n",
    "Ein Dictionary (ADT) wird am besten mit einer Hashtabelle implementiert. Eine einfache Hashfunktion ist beispielsweise $h: k \\mapsto k \\bmod m$ (Kongruenz).\n",
    "\n",
    "Damit auch nicht natürlich-zahlige Schlüssel, z.B. Zeichenketten, verwendet werden können, wird eine sogenannte *pre-hash-Funktion* benötigt. Diese ist eine Funktion, die vom Schlüsseluniversum auf eine nicht-negative ganze Zahl abbildet. Theoretisch betrachtet ist dies immer möglich, da alles, was in einem Computer dargestellt wird, diskret und endlich ist. Schließlich könnte man die Bits, durch welche das entsprechende Datum dargestellt wird, als nicht-negativen Integer auffassen und diesen als den *pre-hash-Wert* nehmen. Dies würde jedoch mitunter zu sehr großen Zahlen führen, weshalb man in der Praxis meist bessere pre-hash-Funktionen verwendet. Hat man beispielsweise eine Zeichenkette mit Zeichen aus <tt>a-z</tt>, so könnte man diese Zeichenkette als Zahl im Stellenwertsystem mit der Basis $26$ auffassen.\n",
    "\n",
    "__Beispiel__:\n",
    "\n",
    "$h($\"adf\"$) = 0 \\cdot 26^2 + 3 \\cdot 26 + 5 \\cdot 1 = 83$\n",
    "\n",
    "Nun kann man mit dem \"geprehashten\" Wert, der eine natürliche Zahl ist, so umgehen, als wäre dieser der eigentliche Schlüssel. \n",
    "\n",
    "In der Programmiersprache Java beispielsweise findet dieses Pre-Hashing durch die `hashCode()`-Methode, die jede Klasse implementiert, statt.\n",
    "\n",
    "## Kollisionen\n",
    "\n",
    "Da $h$ wegen $m \\ll \\left| U \\right|$ im Allgemeinen nicht injektiv ist, kann es zu Kollisionen kommen.\n",
    "Eine **Kollision** unter der Hashfunktion $h$ tritt auf, wenn für $k_i, k_j \\in K$ mit $k_i \\neq k_j$ gilt $h(k_i) = h(k_j)$.\n",
    "\n",
    "<img src=\"http://www.cs.fsu.edu/~burmeste/slideshow/images_content/figure12_2.gif\" width=\"450\">\n",
    "\n",
    "Eine Kollision ergibt sich, wenn zwei oder mehrere unterschiedliche Schlüssel den gleichen Hash-Wert haben. Dies hat zur Folge, dass sie sich den gleichen Slot in der Hash Map teilen müssten. Um dieses Problem zu behandeln, gibt es mehrere Verfahren. Im Folgenden werden **Hashing with Chaining** und **Open Addressing** vorgestellt.\n",
    "\n",
    "### Hashing with Chaining\n",
    "\n",
    "Bei __Hashing with Chaining__ wird in einem Slot der Hash Table anstatt eines Wertes eine *Linked List* von Schlüssel-Wert-Paaren gespeichert. Kommt es beim Einfügen (Operation `insert`) zu einer Kollision, so fügt man das Schlüssel-Wert-Paar ans Ende dieser Liste ein. Möchte man nach einem Schlüssel suchen (Operation `get`), so muss man durch die Liste an dem entsprechenden Slot iterieren. \n",
    "\n",
    "<img src=\"http://www.cs.fsu.edu/~burmeste/slideshow/images_content/figure12_3.gif\" width=\"450\">\n",
    "\n",
    "Für die Implementation nutzen wir die SinglyLinkedList, die bereits in Kapitel 3 implementiert wurde. Der Einfachkeit halber, wird auf die Implementation der __remove__-Methode verzichtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashing\n",
      "with\n",
      "Chaining\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.value = None\n",
    "        self.next = None\n",
    "\n",
    "    def add(self, value, index):\n",
    "        if index > 1 and self.next is not None:\n",
    "            return self.next.add(value, index - 1)\n",
    "        elif index == 1:\n",
    "            new_node = Node()\n",
    "            new_node.value = value\n",
    "            new_node.next = self.next\n",
    "            self.next = new_node\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "class SinglyLinkedList:\n",
    "    def __init__(self):\n",
    "        self.head = Node()\n",
    "        self.length = 0\n",
    "\n",
    "    def add(self, value, index=None):\n",
    "        if index is None:\n",
    "            index = self.length\n",
    "        if index == 0:\n",
    "            new_node = Node()\n",
    "            new_node.value = value\n",
    "            new_node.next = self.head\n",
    "            self.head = new_node\n",
    "            self.length += 1\n",
    "        elif 0 < index <= self.length:\n",
    "            if self.head.add(value, index):\n",
    "                self.length += 1\n",
    "\n",
    "\n",
    "class HashTable:\n",
    "    def __init__(self):\n",
    "        self.table = []\n",
    "        for i in range(m):\n",
    "            self.table.append(SinglyLinkedList())\n",
    "\n",
    "    # hash function of the hash table, using a really simple one here\n",
    "    @staticmethod\n",
    "    def __hash(key):\n",
    "        return hash(key) % m\n",
    "\n",
    "    def insert(self, key, value):\n",
    "        self.table[HashTable.__hash(key)].add((key, value))\n",
    "        \n",
    "    def get(self, key):\n",
    "        node = self.table[HashTable.__hash(key)].head\n",
    "        while node is not None:\n",
    "            if node.value is not None and node.value[0] == key:\n",
    "                return node.value[1]\n",
    "            node = node.next\n",
    "        return None\n",
    "    \n",
    "    \n",
    "hash_table = HashTable()\n",
    "\n",
    "# now our hash table allows us to use any data type as key, in this case a string\n",
    "hash_table.insert('a', 'Hashing')\n",
    "hash_table.insert('b', 'Chaining')\n",
    "hash_table.insert('c', 'with')\n",
    "\n",
    "print(hash_table.get('a'))\n",
    "print(hash_table.get('c'))\n",
    "print(hash_table.get('b'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handelt es sich um eine sehr schlechte Hashfunktion, bei der es viele Kollisionen gibt, so kann es im Extrem passieren, dass (fast) alle Schlüssel den gleichen Hash-Wert haben und somit genau eine Linked List der Länge $n$ bilden. $n$ ist dabei die Anzahl der Elemente in der Datenstruktur, $n = \\left| K \\right|$. Die worst-case Komplexität liegt somit für alle Operationen in $\\mathcal{O}(n)$. Für gute Hashfunktionen tritt dieser worst-case jedoch mit einer sehr geringen Wahrscheinlichkeit ein. Man kann $\\mathcal{O}(\\log n)$ im worst-case erreichen, indem man statt Linked Lists ballancierte Bäume verwendet.\n",
    "\n",
    "### Simple Uniform Hashing\n",
    "\n",
    "Man spricht von Simple Uniform Hashing, wenn die Hashfunktion $h$ die Schlüsselmenge $K$ uniform zufällig auf die Werte $\\{0, 1, \\dotsc, m-1\\}$ verteilt. *Uniform zufällig* bedeutet, dass jeder Hash-Wert gleich wahrscheinlich auftreten kann, so als ob man den Hash-Wert in einem Zufallsexperiment bestimmt. \n",
    "\n",
    "Die Annahme, dass die Verteilung der Hash-Werte uniform ist, tritt in der Praxis nicht ein, jedoch hilft diese Annahme um zu verstehen, warum Operationen in einer Hashtable eine erwartete Laufzeit von $\\mathcal{O}(1)$ haben:\n",
    "\n",
    "Der Erwartungswert für die Anzahl der Elemente in einem Slot unter der Annahme von Uniform Hashing ist $n \\cdot \\frac{1}{m} = \\frac{n}{m}$. Nehmen wir an, dass $n \\in \\mathcal{O}(m)$, also die Anzahl der Elemente $n$ maximal ein Vielfaches (Konstante als Faktor) von der Anzahl der Slots $m$ ist, so befinden sich voraussichtlich $\\leqslant \\frac{c \\cdot m}{m} = c$ Elemente in einer Liste. Da $c$ eine Konstante ist, befinden sich lediglich $\\mathcal{O}(1)$ Elemente in einer Liste.\n",
    "<!-- div style=\"text-align: right; font-size: 24px;\">&#9633;</div -->\n",
    "\n",
    "### Table Doubling\n",
    "\n",
    "Das Problem ist, dass $n$ nicht vorhersagbar ist; schließlich können ständig Werte in das Dictionary eingefügt und daraus entfernt werden. Ist $n$ nämlich viel größer als $m$, so sind die Listen, durch die iteriert werden muss, sehr lang und somit wäre die Datenstruktur ineffizient. Wie kann man also sicherstellen, dass $n \\in \\mathcal{O}(m)$ immer gilt? Hierfür wird eine Technik angewandt, die bereits von dynamischen Arrays bekannt ist, nämlich das Verdoppeln der Größe, sobald die Anzahl der Elemente zu groß wird. Man spricht hier von Table Doubling.\n",
    "\n",
    "Table Doubling wird durchgeführt, sobald $n > m$. Dabei wird die Anzahl der Slots $m$ verdoppelt. Die Anzahl der Slots nach Table Doubling ist dann $m'=2m$. Um die Elemente nun auf $m'$ Slots zu verteilen, ist eine neue Hashfunktion nötig. Handelt es sich zunächst beispielsweise um die sehr einfache Hashfunktion $h: x \\mapsto x \\bmod m$, so wird sie entsprechend zu $h': x \\mapsto x \\bmod m'$ abgeändert. Die bereits eingefügten Elemente werden nun nach der neuen Hashfunktion $h'$ neu eingefügt, man spricht hier von *Rehashing*. Die Kosten für die ganze Table Doubling Operation betragen $\\mathcal{O}(n)$. Analog wie für dynamische Arrays kann man aber zeigen, dass die Kosten amortisiert weiterhin lediglich $\\mathcal{O}(1)$ betragen.\n",
    "\n",
    "Durch Table Doubling ist sichergestellt, dass $n \\in \\mathcal{O}(m)$ immer gilt und somit die erwartete Laufzeit mit Uniform Hashing $\\mathcal{O}(1)$ beträgt.\n",
    "\n",
    "### Open Addressing\n",
    "\n",
    "Open Addressing ist eine andere Variante, um eine Hash Map zu implementieren. Dabei gibt es keine Verkettung, sondern es wird immer maximal ein Element in einem Slot gespeichert. Somit muss $m \\geqslant n$ gelten. \n",
    "\n",
    "__Insert__\n",
    "\n",
    "Möchte man ein Element einfügen, das einen Hash-Wert hat, welcher einem Slot entspricht, der schon belegt ist, so berechnet man einen neuen Hash und fügt das Element an dieser Stelle ein, falls dieser Slot frei ist. Die Hashfunktion bei Open Addressing ist also eine spezielle Hashfunktion, die nicht nur den Schlüssel als Parameter nimmt, sondern auch die Zahl des Versuches, um den es sich handelt. Die Hashfunktion $h$ ist also von der Form \n",
    "\n",
    "$$\n",
    "h: U \\times \\{0, 1, \\dotsc, m-1\\} \\to \\{0, 1, \\dotsc, m-1\\}.\n",
    "$$\n",
    "\n",
    "Eine entscheidende Anforderung an solch eine Hashfunktion ist, dass der Vektor \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}h(k, 0) & h(k, 1) & \\cdots & h(k, m-1) \\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "mit $k\\in U$ eine Permutation des Vektors \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}0 & 1 & \\cdots & m-1 \\end{pmatrix}\n",
    "$$ \n",
    "\n",
    "ist.\n",
    "\n",
    "Dies bedeutet, dass man nach $m$ Versuchen jeden der $m$ Slots genau einmal \"durchprobiert\" hat. Unter der Bedingung $m \\geqslant n$, findet man demnach in jedem Fall einen freien Slot.\n",
    "\n",
    "__Search__\n",
    "\n",
    "Um einen Schlüssel zu suchen, wendet man die Hashfunktion $h$ ebenfalls mit entsprechendem Versuchszähler an. Man beginnt mit der Versuchszahl 0. Hat man Glück und findet den Schlüssel an dem entsprechenden Slot, so kann man aufhören und hat das Element gefunden. Handelt es sich um einen __null__ Wert, so kann man auch aufhören, mit der Erkenntnis, dass sich der gesuchte Schlüssel nicht in der Hash Map befindet. Findet man an dem entsprechenden Slot, einen anderen Schlüssel, so muss man einen neuen Hash-Wert mit inkrementiertem Versuchszähler berechnen. \n",
    "\n",
    "Dass man bei einem __null__ Wert aufhören kann, liegt daran, dass wenn der gesuchte Schlüssel sich in der Datenstruktur befände, man ihn genau an dieser Stelle eingefügt hätte. Da er sich aber nicht dort befindet, befindet er sich auch nirgendswo anders in der Hash Map.\n",
    "\n",
    "__Remove__\n",
    "\n",
    "Das Entfernen von Schlüsseln aus einer Hash Table mit Open Addressing stellt sich etwas problematisch dar. Entfernt man nämlich ein Element, so funktioniert die Suche nicht mehr, da die Probiersequenz, die zum eigentlichen Schlüssel führen soll, nun durch ein gelöschtes Element unterbrochen wurde und der Suchalgorithmus \"denken\" würde, der Schlüssel befindet sich nicht in der Hash Table. Aus diesem Grund darf man das Element nicht einfach entfernen, sondern man muss einen __deleted__-Marker einführen, der signalisiert, dass man weitersuchen muss, da sich hier mal ein Schlüssel befand. Der Suchalgorithmus bleibt prinzipiell der gleiche. Trifft man auf einen __null__-Wert, so kann man aufhören. Hat man den gesuchten Schlüssel gefunden, so kann man ebenfalls aufhören. Bei jedem anderen Wert - __deleted__-Marker eingeschlossen - muss man mit inkrementiertem Versuchszähler weiterprobieren.\n",
    "\n",
    "Nun stellt sich die Frage, wie man eine Hashfunktion entwickelt, die den Anforderungen von Open Addressing entspricht. Sie muss zusätzlich eine Versuchszahl als Parameter nehmen und alle $m$ Slots genau einmal zurückgeben.\n",
    "\n",
    "#### Linear Probing\n",
    "\n",
    "Die naheliegendste Variante (lineares Sondieren) ist es, einfach beim nächsten Versuch um $i$ Slot(s) weiterzugehen, um auf einen freien Platz zum Schlüsseleintrag zu treffen. Also entwirft man folgende Hashfunktion, wobei $h'$ eine gewöhnliche einstellige Hashfunktion vom Typ $h':U \\mapsto \\{0, 1, \\dotsc, m-1\\}$ ist:\n",
    "\n",
    "$$\n",
    "h(k, i) = (h'(k) + i)\\bmod m\n",
    "$$\n",
    "\n",
    "Diese Hashfunktion ist einfach, aber leider schlecht. Hat sich etwa ein *Cluster* in der Hash Map gebildet, d.h. ein Zustand, bei dem viele Slots unmittelbar hintereinander belegt sind, so muss man definitiv das komplette Cluster durchiterieren, bis man einen freien Platz findet. Zudem hat man jetzt dieses Cluster auch noch um 1 vergrößert. Je größer ein Cluster ist, desto größer ist auch die Wahrscheinlichkeit es beim ersten Versuch zu treffen. Genau genommen $\\frac{k}{m}$, wenn $k$ die Größe des Clusters ist und $m$ die Anzahl der Slots in der Hash Map.\n",
    "\n",
    "#### Double Hashing\n",
    "\n",
    "Double Hashing verwendet zwei zufällig ausgewählte Hashfunktionen $h_1$ und $h_2$. Die Hashfunktion $h$ wird folgendermaßen definiert:\n",
    "\n",
    "$$\n",
    "h(k, i) = \\left( h_1(k) + i h_2(k) \\right) \\bmod m\n",
    "$$\n",
    "\n",
    "Damit sichergestellt ist, dass die Hashfunktion die erforderte Permutation erzeugt, müssen alle Werte von $h_2(k)$ und $m$ relativ prim, also teilerfremd, sein.\n",
    "\n",
    "Diese Hashfunktion erzeugt eine wesentlich durchmischtere Verteilung der Hash-Werte, wodurch sich (wahrscheinlich) keine Cluster bilden und diese somit besser geeignet ist.\n",
    "\n",
    "### Hashfunktionen\n",
    "\n",
    "Bisher wurde geklärt, wie man eine Hashtable implementiert. Nun ist zu klären, wie man eine passende Hashfunktion $h$, die vom Schlüsseluniversum auf $\\{0, 1, \\dotsc, m-1 \\}$ abbildet, konstruiert. Weiter oben haben wir dafür die Divisions- oder Kongruenzmethode verwendet. Im Folgenden werden drei Methoden vorgestellt.\n",
    "\n",
    "#### Divisionsmethode\n",
    "\n",
    "$$\n",
    "h(k) = k \\bmod m\n",
    "$$\n",
    "\n",
    "Diese Hashfunktion ist sehr einfach, jedoch nicht sonderlich gut. Ist $m$ eine Zweierpotenz, was bei Table Doubling immer der Fall ist, so teilt es sich unter Umständen sehr viele Teiler mit dem Schlüssel, was dazu führt, dass bestimmte Hash-Werte unter der Menge $\\{0, 1, \\dotsc, m-1 \\}$ besonders häufig vorkommen. Dies würde zu vielen Kollisionen führen, was die Datenstruktur ineffizient macht.\n",
    "\n",
    "#### Multiplikationsmethode\n",
    "\n",
    "$$\n",
    "h(k) = \\left\\lfloor \\frac{A \\cdot k \\bmod 2^w}{2^{w-r}} \\right\\rfloor\n",
    "$$\n",
    "\n",
    "<img src=\"http://staff.ustc.edu.cn/~csli/graduate/algorithms/book6/229_a.gif\" width=\"350\">\n",
    "\n",
    "Diese Hashfunktion multipliziert den Schlüssel mit einem Faktor $A$. $w$ ist die Wortbreite des Systems. $A$ ist aus der Menge $\\{0, 1, \\dotsc , 2^{w-1} \\}$ zu wählen. Das Ergebnis der Multiplikation $A \\cdot k$ besteht aus $2w$ Bits. Anschließend wird $\\bmod 2^w$ gebildet, was dazu führt, dass nur die rechten Hälfte, also die rechten $w$ Bits weiter betrachtet werden. Danach wird durch $2^{w-r}$ geteilt, was einem Bitshift von $w-r$ Bits entspricht. Als Ergebnis bleibt ein Wert mit $r$ Bits übrig. $r$ ist dabei so zu wählen, dass gilt $m=2^r$.\n",
    "\n",
    "Diese Hashfunktion ist besser, da hier ein Durchmischen stattfindet und somit die Hashwerte besser, also gleichmäßiger, verteilt sind.\n",
    "\n",
    "#### Universelles Hashing\n",
    "\n",
    "Eine Möglichkeit für universelles Hashing ist die Klasse folgender Hashfunktionen:\n",
    "\n",
    "$$\n",
    "h(k) = ((a \\cdot k + b) \\bmod p) \\bmod m\n",
    "$$\n",
    "\n",
    "$p$ ist dabei eine Primzahl, für die gilt $p \\geqslant m$. Wird eine Hashfunktion benötigt, so werden $a$ und $b$ zufällig aus der Menge $\\{0, 1, \\dotsc, p-1\\}$ gewählt. Damit die Hash-Werte uniform auf $\\{0, 1, \\dotsc, m-1\\}$ verteilt werden, müssen $p$ und $m$ teilerfremd sein. Durch die Bedingung, dass $p$ eine Primzahl ist, ist dies gegeben.\n",
    "\n",
    "Da $a$ und $b$ zufällig gewählt werden, handelt es sich hierbei um eine Menge bzw. Klasse $\\mathcal{H}$ von Hashfunktionen, die aus $p^2$ Funktionen besteht. Die hier vorgestellte Klasse von Hashfunktionen ist $\\approx 1$-universell.\n",
    "\n",
    "Eine Klasse $\\mathcal{H}$ von Hashfunktionen ist **$c$-universell**, wenn für alle $x, y \\in U$ mit $x \\neq y$ mit zufällig ausgewählten $h \\in \\mathcal{H}$ gilt, dass $Pr(h(x) = h(y)) \\leqslant c \\cdot \\frac{1}{m}$.\n",
    "\n",
    "Ist die Klasse $\\mathcal{H}$ 1-universell, so ist bei zufällig ausgewähltem $h$ die Wahrscheinlichkeit einer Kollision $\\leqslant \\frac{1}{m}$. Anders fomulliert gibt es nicht mehr als $c \\cdot \\frac{\\left| \\mathcal{H} \\right|}{m}$ Hashfunktionen, die für ein Schlüsselpaar den gleichen Hash-Wert liefern.\n",
    "\n",
    "Auf den Beweis, dass die genannte Klasse von Hashfunktionen universell ist, wird verzichtet.\n",
    "\n",
    "# String Matching\n",
    "\n",
    "String Matching ist ein Problem, bei dem es darum geht, in einem String einen bestimmten Substring zu finden. Dies ist ein Problem, welches in der Praxis sehr häufig auftritt, beispielsweise in Texteditoren bei der Suche mit CTRL+F oder beim Linux Tool `grep`. In beiden Beispielen geht es darum, in einer sehr großen Datei, also einem String (Zeichenkette), einen bestimmten Substring zu finden, bzw. herauszufinden, ob dieser überhaupt vorkommt.\n",
    "\n",
    "Ein naiver Ansatz ist es, jede Position der Zeichenkette der Länge $n$ als potenzielle Startposition des $k$-langen Substrings anzusehen und durch Zeichenvergleich ($k$ Zeichen) zu prüfen. $n$ ist die Länge des Strings und $k$ die Länge des Substrings. Dieser Algorithmus hat einen Zeitaufwand von $\\mathcal{O}(nk)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "def string_matching(str, substr):\n",
    "    for i in range(len(str) - len(substr) + 1):\n",
    "        match = True\n",
    "        for j in range(len(substr)):\n",
    "            if str[i + j] != substr[j]:\n",
    "                match = False\n",
    "        if match:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "\n",
    "print(string_matching('Just using a naive string matching approach', 'string matching'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karp-Rabin Algorithmus\n",
    "\n",
    "Der Karp-Rabin Algorithmus ermöglicht es, das String Matching Problem in einer besseren Laufzeit als $\\mathcal{O}(nk)$ zu lösen. Dabei wird das Prinzip von Hashes genutzt. Anstatt aber beim Durchiterieren jedesmal einen neuen Hash zu berechnen, nutzt man die Tatsache, dass sich beim Verschieben des Schiebefensters, welcher den Substring, der gerade untersucht wird, darstellt, sich nur das erste und letzte Zeichen ändern und die Mitte des Substrings gleich bleibt. Konstruiert man die Hashfunktion so, dass man den String als Zahl mit der Basis, die der Größe des Alphabets entspricht, auffasst, so kann man den Hash nach Entfernen des ersten Zeichens und Anfügen eines neuen Zeichens, mit Hilfe von einfachen Rechenoperationen in konstanter Zeit berechnen.\n",
    "\n",
    "__Beispiel für einen Hash mit Basis 26: __\n",
    "$h($\"hash\"$) = 7 \\cdot 26^3 + 0 \\cdot 26^2 + 18 \\cdot 26 + 7 \\cdot 1 = 123507$\n",
    "\n",
    "Fügt man jetzt z.B. das Zeichen x hinzu, so müsste man zunächst die Zahl $(7,0,18,7)_{26}$ mit der Basis multiplizieren, also erhält man $(7,0,18,7,0)_{26}$. Diese Operation ist äquivalent zur Multiplikation mit 10 im Dezimalsystem. Nun addiert man den Wert des neuen Zeichens, nämlich 23 und erhält $(7,0,18,7,23)_{26}$.\n",
    "\n",
    "Nun benötigt man eine Rechenoperation, mit der man das erste Zeichen entfernen kann. Man muss also die erste Ziffer abschneiden. Dies führt man durch, indem man die Hash-Zahl modulo $\\text{Basis}^{\\text{Länge des Strings - 1}}$ nimmt. In diesem Fall $\\bmod 26^4$ und man erhält $(0,18,7,23)_{26}$.\n",
    "\n",
    "Mit Hilfe dieser Arithmetik kann man nun eine Datenstruktur names **Rolling Hash** implementieren, die in konstanter Zeit ein Zeichen anfügt, in konstanter Zeit das erste Zeichen entfernt und in konstanter Zeit den aktuellen Hash-Wert zurückgibt.\n",
    "\n",
    "Der Algorithmus iteriert nun durch $n$ Zeichen des Strings und vergleicht den Rolling Hash-Wert *des Substrings ab dem entsprechenden Index* mit dem Rolling Hash-Wert *des gesuchten Substrings*, der im Voraus berechnet wurde. Da die Basis nicht der Größe des Alphabets entspricht, dies auch für UNICODE-Zeichen nicht praktikabel wäre, kommt es zu Kollisionen, d.h. unterschiedliche Strings können den gleichen Hash-Wert haben. Dadurch muss man im positiven Fall, d.h. die Hash-Werte stimmen überein, beide Strings noch Zeichen für Zeichen überprüfen. Da aber Kollisionen sehr selten sind, hat das keinen bedeutenden Einfluss auf die erwartete Laufzeit des Algorithmus'.\n",
    "\n",
    "Die erwartete Laufzeit des Algorithmus beträgt $\\mathcal{O}(n+k)$, da man zunächst einen Aufwand von $k$ hat, um den Rolling Hash des gesuchten Substrings zu berechnen und anschließend $n$-mal (erwarteten) konstanten Aufwand hat, um den Rolling Hash mit den __append__- und __skip__- Operationen anzupassen und ihn entsprechend abzugleichen. Dieser Algorithmus ist im Vergleich zum naiven Brute-Force Ansatz besonders effizient, wenn $k$, also die Länge des Substrings, groß ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "class RollingHash:\n",
    "    def __init__(self):\n",
    "        self.string = ''\n",
    "        self.base = 256\n",
    "        self.hash = 0\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.hash\n",
    "\n",
    "    def append(self, c):\n",
    "        self.hash *= self.base\n",
    "        self.hash += ord(c) % self.base\n",
    "        self.string += c\n",
    "\n",
    "    def skip(self):\n",
    "        if len(self.string) > 0:\n",
    "            self.string = self.string[1:]\n",
    "            self.hash %= self.base ** len(self.string)\n",
    "        else:\n",
    "            raise Exception('string is empty')\n",
    "\n",
    "\n",
    "def karp_rabin(str, substr):\n",
    "    if len(substr) <= len(str):\n",
    "        rolling_hash_substr = RollingHash()\n",
    "        rolling_hash_str = RollingHash()\n",
    "        for i in range(len(substr)):\n",
    "            rolling_hash_substr.append(substr[i])\n",
    "            rolling_hash_str.append(str[i])\n",
    "        hash_value_substr = hash(rolling_hash_substr)\n",
    "        if hash_value_substr == hash(rolling_hash_str):\n",
    "            if rolling_hash_str.string == substr:\n",
    "                return 0\n",
    "        for i in range(len(substr), len(str)):\n",
    "            rolling_hash_str.skip()\n",
    "            rolling_hash_str.append(str[i])\n",
    "            if hash_value_substr == hash(rolling_hash_str):\n",
    "                if rolling_hash_str.string == substr:\n",
    "                    return i - len(substr) + 1\n",
    "    return None\n",
    "\n",
    "\n",
    "print(karp_rabin('Karp Rabin is awesome.', 'Rabin'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
